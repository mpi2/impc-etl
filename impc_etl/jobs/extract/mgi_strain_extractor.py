"""

[MGI strain report](http://www.informatics.jax.org/downloads/reports/MGI_Strain.rpt) extraction Task. This report maps
the MGI accession IDs for the strains with the corresponding Strain name and Strain type.

### From [MGI Reports / Strains and Polymorphisms section](http://www.informatics.jax.org/downloads/reports/index.html#strain):

#### 1. Official Strain Nomenclature (tab-delimited):

| MGI Strain ID      | Strain Name | Strain Type|
| ----------- | ----------- | ----------- |
|MGI:2160170|101|inbred strain|
...
"""
import luigi
from luigi.contrib.spark import PySparkTask
from pyspark import SparkContext
from pyspark.sql import DataFrame, SparkSession
from pyspark.sql.types import StructType, StructField, StringType

from impc_etl.shared.utils import extract_tsv
from impc_etl.workflow.config import ImpcConfig

STRAIN_SCHEMA = StructType(
    [
        StructField("mgiStrainID", StringType(), True),
        StructField("strainName", StringType(), True),
        StructField("strainType", StringType(), True),
    ]
)


class MGIStrainReportExtractor(PySparkTask):
    """
    PySpark Task class to extract the information from the
    [MGI strain report](http://www.informatics.jax.org/downloads/reports/MGI_Strain.rpt).
    It also adds a header to the RPT format content (mgiStrainID, strainName, strainType).
    """

    #: Name of the Spark task
    name = "IMPC_MGI_Strain_Report_Extractor"

    #: Path of the MGI Strain report *.rpt file.
    mgi_strain_report_path: luigi.Parameter = luigi.Parameter()

    #: Path of the output directory where ethe new parquet file will be generated.
    output_path: luigi.Parameter = luigi.Parameter()

    def output(self):
        """
        Returns the full parquet path as an output for the Luigi Task
        (e.g. impc/dr15.2/parquet/mgi_strain_parquet)
        """
        return ImpcConfig().get_target(f"{self.output_path}mgi_strain_parquet")

    def app_options(self):
        """
        Generates the options pass to the PySpark job
        """
        return [
            self.mgi_strain_report_path,
            self.output().path,
        ]

    def main(self, sc: SparkContext, *args):
        """
        Takes in a SparkContext and the list of arguments generated by `app_options` and executes the PySpark job.
        """
        mgi_strain_report_path = args[0]
        output_path = args[1]

        spark = SparkSession(sc)

        strain_df: DataFrame = extract_tsv(
            spark, mgi_strain_report_path, schema=STRAIN_SCHEMA, header=False
        )
        strain_df.write.mode("overwrite").parquet(output_path)
