import os

import luigi
from luigi.contrib.external_program import ExternalProgramTask
from luigi.contrib.spark import PySparkTask
from luigi.contrib.webhdfs import WebHdfsClient
from pyspark import SparkContext
from pyspark.sql import SparkSession
from pyspark.sql.functions import expr

from impc_etl.workflow.normalization import *
import glob
import requests


class ParquetJSONSolrMapper(PySparkTask):
    """
    PySpark Task class to extract GenTar Product report data.
    """

    #: Name of the Spark task
    name: str = "ParquetJSONSolrMapper"

    parquet_path = luigi.Parameter()
    dev_solr_host = luigi.Parameter()
    core_name = luigi.Parameter()
    partition_size = luigi.IntParameter(default=100)

    #: Path of the output directory where the new parquet file will be generated.
    output_path: luigi.Parameter = luigi.Parameter()

    def output(self):
        """
        Returns the full parquet path as an output for the Luigi Task
        (e.g. impc/dr15.2/parquet/product_report_parquet)
        """
        return ImpcConfig().get_target(f"{self.output_path}/{self.core_name}_json")

    def app_options(self):
        """
        Generates the options pass to the PySpark job
        """
        return [
            self.parquet_path,
            self.dev_solr_host,
            self.core_name,
            self.partition_size,
            self.output().path,
        ]

    def main(self, sc: SparkContext, *args):
        """
        Takes in a SparkContext and the list of arguments generated by `app_options` and executes the PySpark job.
        """
        spark = SparkSession(sc)

        parquet_path = args[0]
        dev_solr_host = args[1]
        core_name = args[2]
        partition_size = args[3]
        output_path = args[4]

        # Load Parquet data into a DataFrame
        parquet_df = spark.read.parquet(parquet_path)

        # Extract column names and types from Solr schema
        schema_url = f"{dev_solr_host}/solr/{core_name}/schema/fields"
        response = requests.get(schema_url)
        schema_data = response.json()
        field_types = {field["name"]: field["type"] for field in schema_data["fields"]}

        # Filter DataFrame to include only columns present in Solr schema
        columns_to_keep = [
            field["name"]
            for field in schema_data["fields"]
            if field["name"] in parquet_df.columns
        ]
        filtered_df = parquet_df.select(*columns_to_keep)

        # Convert certain columns to float64
        for col_name, col_type in field_types.items():
            if col_name in parquet_df.columns and col_type in [
                "plong",
                "pint",
                "pdouble",
                "pdouble",
                "pfloat",
                "pfloats",
                "pints",
                "plong",
                "plongs",
            ]:
                filtered_df = filtered_df.withColumn(
                    col_name, filtered_df[col_name].cast("double")
                )

        filtered_df = filtered_df.withColumn("id", expr("uuid()"))

        filtered_df.repartition(partition_size).write.json(
            output_path,
            mode="overwrite",
            compression="gzip",
        )


class ParquetSolrLoader(ExternalProgramTask):

    parquet_path = luigi.Parameter()
    dev_solr_host = luigi.Parameter()
    core_name = luigi.Parameter()
    partition_size = luigi.IntParameter(default=10)
    solr_workdir = luigi.Parameter()
    solr_scripts_path = luigi.Parameter()
    solr_post_path = luigi.Parameter()
    solr_port = luigi.IntParameter(default=8986)
    big_task = luigi.Parameter(False)

    #: Path of the output directory where the new parquet file will be generated.
    solr_json_path: luigi.Parameter = luigi.Parameter()

    cpus_per_task = 8
    memory_flag = 64
    runtime_flag = 60
    multiplier = 1

    def requires(self):
        return ParquetJSONSolrMapper(
            parquet_path=self.parquet_path,
            solr_host=self.dev_solr_host,
            core_name=self.core_name,
            partition_size=self.partition_size,
            output_path=self.solr_json_path,
        )

    def output(self):
        return luigi.LocalTarget(f"{self.solr_json_path}/_INDEX_SUCCESS")

    def program_args(self):
        if self.big_task:
            self.multiplier = 2
        return [
            "srun",
            "--cpus-per-task",
            self.cpus_per_task * self.multiplier,
            "--mem",
            f"{self.memory_flag * self.multiplier}G",
            "-t",
            self.runtime_flag * self.multiplier * 4,
            os.getcwd() + "/lib/index_directory.sh",
            self.solr_scripts_path,
            self.solr_post_path,
            self.solr_port,
            self.input().path,
            self.core_name,
        ]


class Parquet2Solr(SparkSubmitTask):
    app = "lib/parquet2solr-0.0.1-SNAPSHOT.jar"
    name = "IMPC_Parquet2Solr"
    input_path = luigi.Parameter()
    output_path = luigi.Parameter()
    parquet_name = ""
    solr_core_name = ""
    parquet_solr_map = {
        "observations_parquet": "experiment",
        "statistical_results_raw_data_include_parquet": "statistical-result",
        "statistical_results_raw_data_include_parquet_raw_data": "statistical-raw-data",
        "gene_data_include_parquet": "gene",
        "genotype_phenotype_parquet": "genotype-phenotype",
        "mp_parquet": "mp",
        "impress_parameter_parquet": "pipeline",
        "product_report_raw_parquet": "product",
        "mgi_phenotype_parquet": "mgi-phenotype",
        "impc_images_core_parquet": "impc_images",
    }

    def output(self):
        self.output_path = (
            self.output_path + "/"
            if not self.output_path.endswith("/")
            else self.output_path
        )
        self.parquet_name = os.path.basename(os.path.normpath(self.input_path))
        self.solr_core_name = self.parquet_solr_map[self.parquet_name]
        return ImpcConfig().get_target(f"{self.output_path}{self.solr_core_name}_index")

    def app_options(self):
        return [
            self.app,
            self.input_path,
            self.solr_core_name,
            "false",
            "false",
            self.output().path,
        ]


class ImpcCopyIndexParts(luigi.Task):
    parquet_path = luigi.Parameter()
    solr_path = luigi.Parameter()
    local_path = luigi.Parameter()
    solr_core_name = ""

    def requires(self):
        return [
            Parquet2Solr(input_path=self.parquet_path, output_path=self.solr_path),
        ]

    def output(self):
        self.local_path = (
            self.local_path + "/"
            if not self.local_path.endswith("/")
            else self.local_path
        )
        self.solr_core_name = os.path.basename(os.path.normpath(self.input()[0].path))
        return luigi.LocalTarget(f"{self.local_path}{self.solr_core_name}")

    def run(self):
        client = WebHdfsClient()
        client.download(self.input()[0].path, self.output().path, n_threads=50)


class ImpcMergeIndex(ExternalProgramTask):
    parquet_path = luigi.Parameter()
    solr_path = luigi.Parameter()
    local_path = luigi.Parameter()
    big_task = luigi.Parameter(False)
    solr_core_name = ""
    cpus_per_task = 8
    memory_flag = 64
    runtime_flag = 60
    multiplier = 1

    def program_args(self):
        if self.big_task:
            self.multiplier = 3
        return [
            "srun",
            "--cpus-per-task",
            self.cpus_per_task * self.multiplier,
            "--mem",
            f"{self.memory_flag * self.multiplier}G",
            "-t",
            self.runtime_flag * self.multiplier,
            "java",
            "-jar",
            f"-Xmx{(self.memory_flag * 1024 * self.multiplier) - 1024}m",
            os.getcwd() + "/lib/impc-merge-index-1.0-SNAPSHOT.jar",
            self.output().path,
        ] + [
            path_name
            for path_name in glob.glob(self.input()[0].path + "/*/data/index/")
            if "*" not in path_name
        ]

    def requires(self):
        return [
            Parquet2Solr(input_path=self.parquet_path, output_path=self.solr_path),
        ]

    def output(self):
        self.local_path = (
            self.local_path + "/"
            if not self.local_path.endswith("/")
            else self.local_path
        )
        self.solr_core_name = os.path.basename(os.path.normpath(self.input()[0].path))
        return luigi.LocalTarget(f"{self.local_path}{self.solr_core_name}_merged")
