<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>impc_etl.jobs.clean.specimen_cleaner API documentation</title>
<meta name="description" content="Luigi PySpark task that takes the Specimen data coming from the different
data sources
(e.g. IMPC, 3i, EuroPhenome, PWG)
and applies some data …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>impc_etl.jobs.clean.specimen_cleaner</code></h1>
</header>
<section id="section-intro">
<p>Luigi PySpark task that takes the Specimen data coming from the different
data sources
(e.g. IMPC, 3i, EuroPhenome, PWG)
and applies some data sanitizing functions.</p>
<p>The cleaning process includes:</p>
<ul>
<li>mapping identifiers</li>
<li>dropping entries with required values as NULL</li>
<li>drop a list of predefined skipped experiments</li>
<li>sanitize identifiers with XML elements (e.g. gt;)</li>
<li>cleaning legacy identifiers</li>
<li>drop duplicate specimen entries</li>
<li>lastly generate a unique id</li>
</ul>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
    Luigi PySpark task that takes the Specimen data coming from the different  data sources  (e.g. IMPC, 3i, EuroPhenome, PWG)
    and applies some data sanitizing functions.

    The cleaning process includes:

    - mapping identifiers
    - dropping entries with required values as NULL
    - drop a list of predefined skipped experiments
    - sanitize identifiers with XML elements (e.g. gt;)
    - cleaning legacy identifiers
    - drop duplicate specimen entries
    - lastly generate a unique id

&#34;&#34;&#34;
from typing import Any

import luigi
from luigi.contrib.spark import PySparkTask
from pyspark import SparkContext
from pyspark.sql import SparkSession, DataFrame
from pyspark.sql.functions import udf, when, regexp_replace, col, lit, md5, concat
from pyspark.sql.types import StringType

from impc_etl.shared import utils
from impc_etl.workflow.config import ImpcConfig
from impc_etl.workflow.extraction import MouseSpecimenExtractor, EmbryoSpecimenExtractor


class IMPCSpecimenCleaner(PySparkTask):
    &#34;&#34;&#34;
    PySpark task to clean IMPC Specimen data.

    This task depends on `impc_etl.workflow.extraction.MouseSpecimenExtractor` for cleaning Mouse specimens
    or `impc_etl.workflow.extraction.EmbryoSpecimenExtractor`
    for cleaning Embryo specimens.
    &#34;&#34;&#34;

    #: Name of the Spark task
    name: str = &#34;IMPC_Specimen_Cleaner&#34;

    #: Specimen type can be &#39;mouse&#39; or &#39;embryo&#39;
    specimen_type: luigi.Parameter = luigi.Parameter()

    #: Path of the output directory where the new parquet file will be generated.
    output_path: luigi.Parameter = luigi.Parameter()

    def requires(self):
        &#34;&#34;&#34;
        Defines the luigi  task dependencies
        &#34;&#34;&#34;
        return (
            MouseSpecimenExtractor()
            if self.specimen_type == &#34;mouse&#34;
            else EmbryoSpecimenExtractor()
        )

    def output(self):
        &#34;&#34;&#34;
        Returns the full parquet path as an output for the Luigi Task
        (e.g. impc/dr15.2/parquet/mouse_specimen_clean_parquet)
        &#34;&#34;&#34;
        return ImpcConfig().get_target(
            f&#34;{self.output_path}{self.specimen_type}_specimen_clean_parquet&#34;
        )

    def app_options(self):
        &#34;&#34;&#34;
        Generates the options pass to the PySpark job
        &#34;&#34;&#34;
        return [
            self.input().path,
            self.output().path,
        ]

    def main(self, sc: SparkContext, *args: Any):
        &#34;&#34;&#34;
        Loads the given Specimen parquet and applies some data sanitizing functions.
        &#34;&#34;&#34;
        input_path = args[0]
        output_path = args[1]
        spark_session = SparkSession.builder.getOrCreate()
        specimen_df = spark_session.read.parquet(input_path)
        specimen_clean_df = self.clean_specimens(specimen_df)
        specimen_clean_df = specimen_clean_df.dropDuplicates(
            [&#34;_specimenID&#34;, &#34;_centreID&#34;]
        )
        specimen_clean_df.write.mode(&#34;overwrite&#34;).parquet(output_path)

    def clean_specimens(self, specimen_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        DCC specimen cleaner
        :return: a clean specimen parquet file
        :rtype: DataFrame
        &#34;&#34;&#34;
        specimen_df: DataFrame = (
            specimen_df.transform(self.map_centre_ids)
            .transform(self.map_project_ids)
            .transform(self.map_production_centre_ids)
            .transform(self.map_phenotyping_centre_ids)
        )

        specimen_df = specimen_df.transform(self.truncate_europhenome_specimen_ids)
        specimen_df = specimen_df.transform(self.truncate_europhenome_colony_ids)
        specimen_df = specimen_df.transform(self.parse_europhenome_colony_xml_entities)
        specimen_df = specimen_df.transform(self.standardize_strain_ids)
        specimen_df = specimen_df.transform(self.override_3i_specimen_data)
        specimen_df = specimen_df.transform(self.generate_unique_id)

        # Some specimen can be found several times in the XML file submitted by the IMPC
        # So it is necessary to drop the duplicates
        specimen_df = specimen_df.drop_duplicates(
            [col_name for col_name in specimen_df.columns if col_name != &#34;_sourceFile&#34;]
        )
        return specimen_df

    def map_centre_ids(self, dcc_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Maps the center ids  found in the XML files to a standard list of ids e.g:
            - gmc -&gt; HMGU
            - h -&gt; MRC Harwell
        The full list of mappings can be found at `impc_etl.config.Constants.CENTRE_ID_MAP`
        &#34;&#34;&#34;
        dcc_df = dcc_df.withColumn(
            &#34;_centreID&#34;, udf(utils.map_centre_id, StringType())(&#34;_centreID&#34;)
        )
        return dcc_df

    def map_project_ids(self, dcc_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Maps the center ids  found in the XML files to a standard list of ids e.g:
            - dtcc -&gt; DTCC
            - riken brc -&gt; RBRC
        The full list of mappings can be found at `impc_etl.config.Constants.PROJECT_ID_MAP`
        &#34;&#34;&#34;
        dcc_df = dcc_df.withColumn(
            &#34;_project&#34;, udf(utils.map_project_id, StringType())(&#34;_project&#34;)
        )
        return dcc_df

    def map_production_centre_ids(self, dcc_experiment_df: DataFrame):
        &#34;&#34;&#34;
        Maps the center ids  found in the XML files to a standard list of ids e.g:
            - gmc -&gt; HMGU
            - h -&gt; MRC Harwell
        The full list of mappings can be found at `impc_etl.config.Constants.CENTRE_ID_MAP`
        &#34;&#34;&#34;
        if &#34;_productionCentre&#34; not in dcc_experiment_df.columns:
            dcc_experiment_df = dcc_experiment_df.withColumn(
                &#34;_productionCentre&#34;, lit(None)
            )
        dcc_experiment_df = dcc_experiment_df.withColumn(
            &#34;_productionCentre&#34;,
            udf(utils.map_centre_id, StringType())(&#34;_productionCentre&#34;),
        )
        return dcc_experiment_df

    def map_phenotyping_centre_ids(self, dcc_experiment_df: DataFrame):
        &#34;&#34;&#34;
        Maps the center ids  found in the XML files to a standard list of ids e.g:
            - gmc -&gt; HMGU
            - h -&gt; MRC Harwell
        The full list of mappings can be found at `impc_etl.config.Constants.CENTRE_ID_MAP`
        &#34;&#34;&#34;
        dcc_experiment_df = dcc_experiment_df.withColumn(
            &#34;_phenotypingCentre&#34;,
            udf(utils.map_centre_id, StringType())(&#34;_phenotypingCentre&#34;),
        )
        return dcc_experiment_df

    def truncate_europhenome_specimen_ids(self, dcc_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Some EuroPhenome Specimen Ids have a suffix that should be truncated, the legacy identifying strategy for Specimen id included
        a suffix tno reference the production/phenotyping Centre (e.g. 232328312_HRW), that suffix needs to be removed.
        &#34;&#34;&#34;
        dcc_df = dcc_df.withColumn(
            &#34;_specimenID&#34;,
            when(
                dcc_df[&#34;_dataSource&#34;].isin([&#34;europhenome&#34;, &#34;MGP&#34;]),
                udf(utils.truncate_specimen_id, StringType())(dcc_df[&#34;_specimenID&#34;]),
            ).otherwise(dcc_df[&#34;_specimenID&#34;]),
        )
        return dcc_df

    def truncate_europhenome_colony_ids(self, dcc_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Some EuroPhenome Colony Ids have a suffix that should be truncated. Same as Specimen IDs some colony IDs used to have a suffix to identify
        the Centre and that has been  removed from the
        tracking system, so we need to truncate them so they  match the corresponding  entry on GenTar.
        &#34;&#34;&#34;
        dcc_df = dcc_df.withColumn(
            &#34;_colonyID&#34;,
            when(
                dcc_df[&#34;_dataSource&#34;] == &#34;europhenome&#34;,
                udf(utils.truncate_colony_id, StringType())(dcc_df[&#34;_colonyID&#34;]),
            ).otherwise(dcc_df[&#34;_colonyID&#34;]),
        )
        return dcc_df

    def parse_europhenome_colony_xml_entities(self, dcc_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Some EuroPhenome Colony Ids have &amp;lt; &amp;gt; values that have to be replaced by the  corresponding characters &lt; and &gt;.
        &#34;&#34;&#34;
        dcc_df = dcc_df.withColumn(
            &#34;_colonyID&#34;,
            when(
                (dcc_df[&#34;_dataSource&#34;] == &#34;europhenome&#34;),
                regexp_replace(&#34;_colonyID&#34;, &#34;&amp;lt;&#34;, &#34;&lt;&#34;),
            ).otherwise(dcc_df[&#34;_colonyID&#34;]),
        )

        dcc_df = dcc_df.withColumn(
            &#34;_colonyID&#34;,
            when(
                (dcc_df[&#34;_dataSource&#34;] == &#34;europhenome&#34;),
                regexp_replace(&#34;_colonyID&#34;, &#34;&amp;gt;&#34;, &#34;&gt;&#34;),
            ).otherwise(dcc_df[&#34;_colonyID&#34;]),
        )
        return dcc_df

    def standardize_strain_ids(self, dcc_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Some strain IDs are provided as MGI identifiers and some others don&#39;t, some of the ones provided as MGI identifiers lack the  &#39;MGI:&#39;,
        here we remove the &#39;MGI:&#39; from al of them to be able to process them in a consistent way in future tasks.
        &#34;&#34;&#34;
        dcc_df = dcc_df.withColumn(
            &#34;_strainID&#34;, regexp_replace(dcc_df[&#34;_strainID&#34;], &#34;MGI:&#34;, &#34;&#34;)
        )
        return dcc_df

    def override_3i_specimen_data(self, dcc_specimen_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Whenever a Specime is presetn both in the 3i project and any other data source (e.g. EuroPhenome or IMPC) the other data source specimen data should be used instead of the 3i one.
        &#34;&#34;&#34;
        dcc_specimen_df_a = dcc_specimen_df.alias(&#34;a&#34;)
        dcc_specimen_df_b = dcc_specimen_df.alias(&#34;b&#34;)
        dcc_specimen_df = dcc_specimen_df_a.join(
            dcc_specimen_df_b,
            (dcc_specimen_df_a[&#34;_specimenID&#34;] == dcc_specimen_df_b[&#34;_specimenID&#34;])
            &amp; (dcc_specimen_df_a[&#34;_centreID&#34;] == dcc_specimen_df_b[&#34;_centreID&#34;])
            &amp; (dcc_specimen_df_a[&#34;_dataSource&#34;] != dcc_specimen_df_b[&#34;_dataSource&#34;]),
            &#34;left_outer&#34;,
        )
        dcc_specimen_df = dcc_specimen_df.where(
            col(&#34;b._specimenID&#34;).isNull()
            | ((col(&#34;b._specimenID&#34;).isNotNull()) &amp; (col(&#34;a._dataSource&#34;) != &#34;3i&#34;))
        )
        return dcc_specimen_df.select(&#34;a.*&#34;).dropDuplicates()

    def generate_unique_id(self, dcc_specimen_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Generates an unique identifier for the  Specimen using productin centre, phenotyping centre  and specimen ID.
        &#34;&#34;&#34;
        dcc_specimen_df = dcc_specimen_df.withColumn(
            &#34;unique_id&#34;,
            md5(
                concat(
                    *[
                        when(
                            col(&#34;_productionCentre&#34;).isNotNull(),
                            col(&#34;_productionCentre&#34;),
                        )
                        .when(
                            col(&#34;_phenotypingCentre&#34;).isNotNull(),
                            col(&#34;_phenotypingCentre&#34;),
                        )
                        .otherwise(lit(&#34;&#34;)),
                        col(&#34;_specimenID&#34;),
                    ]
                )
            ),
        )
        return dcc_specimen_df</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner"><code class="flex name class">
<span>class <span class="ident">IMPCSpecimenCleaner</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>PySpark task to clean IMPC Specimen data.</p>
<p>This task depends on <code><a title="impc_etl.workflow.extraction.MouseSpecimenExtractor" href="../../workflow/extraction.html#impc_etl.workflow.extraction.MouseSpecimenExtractor">MouseSpecimenExtractor</a></code> for cleaning Mouse specimens
or <code><a title="impc_etl.workflow.extraction.EmbryoSpecimenExtractor" href="../../workflow/extraction.html#impc_etl.workflow.extraction.EmbryoSpecimenExtractor">EmbryoSpecimenExtractor</a></code>
for cleaning Embryo specimens.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class IMPCSpecimenCleaner(PySparkTask):
    &#34;&#34;&#34;
    PySpark task to clean IMPC Specimen data.

    This task depends on `impc_etl.workflow.extraction.MouseSpecimenExtractor` for cleaning Mouse specimens
    or `impc_etl.workflow.extraction.EmbryoSpecimenExtractor`
    for cleaning Embryo specimens.
    &#34;&#34;&#34;

    #: Name of the Spark task
    name: str = &#34;IMPC_Specimen_Cleaner&#34;

    #: Specimen type can be &#39;mouse&#39; or &#39;embryo&#39;
    specimen_type: luigi.Parameter = luigi.Parameter()

    #: Path of the output directory where the new parquet file will be generated.
    output_path: luigi.Parameter = luigi.Parameter()

    def requires(self):
        &#34;&#34;&#34;
        Defines the luigi  task dependencies
        &#34;&#34;&#34;
        return (
            MouseSpecimenExtractor()
            if self.specimen_type == &#34;mouse&#34;
            else EmbryoSpecimenExtractor()
        )

    def output(self):
        &#34;&#34;&#34;
        Returns the full parquet path as an output for the Luigi Task
        (e.g. impc/dr15.2/parquet/mouse_specimen_clean_parquet)
        &#34;&#34;&#34;
        return ImpcConfig().get_target(
            f&#34;{self.output_path}{self.specimen_type}_specimen_clean_parquet&#34;
        )

    def app_options(self):
        &#34;&#34;&#34;
        Generates the options pass to the PySpark job
        &#34;&#34;&#34;
        return [
            self.input().path,
            self.output().path,
        ]

    def main(self, sc: SparkContext, *args: Any):
        &#34;&#34;&#34;
        Loads the given Specimen parquet and applies some data sanitizing functions.
        &#34;&#34;&#34;
        input_path = args[0]
        output_path = args[1]
        spark_session = SparkSession.builder.getOrCreate()
        specimen_df = spark_session.read.parquet(input_path)
        specimen_clean_df = self.clean_specimens(specimen_df)
        specimen_clean_df = specimen_clean_df.dropDuplicates(
            [&#34;_specimenID&#34;, &#34;_centreID&#34;]
        )
        specimen_clean_df.write.mode(&#34;overwrite&#34;).parquet(output_path)

    def clean_specimens(self, specimen_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        DCC specimen cleaner
        :return: a clean specimen parquet file
        :rtype: DataFrame
        &#34;&#34;&#34;
        specimen_df: DataFrame = (
            specimen_df.transform(self.map_centre_ids)
            .transform(self.map_project_ids)
            .transform(self.map_production_centre_ids)
            .transform(self.map_phenotyping_centre_ids)
        )

        specimen_df = specimen_df.transform(self.truncate_europhenome_specimen_ids)
        specimen_df = specimen_df.transform(self.truncate_europhenome_colony_ids)
        specimen_df = specimen_df.transform(self.parse_europhenome_colony_xml_entities)
        specimen_df = specimen_df.transform(self.standardize_strain_ids)
        specimen_df = specimen_df.transform(self.override_3i_specimen_data)
        specimen_df = specimen_df.transform(self.generate_unique_id)

        # Some specimen can be found several times in the XML file submitted by the IMPC
        # So it is necessary to drop the duplicates
        specimen_df = specimen_df.drop_duplicates(
            [col_name for col_name in specimen_df.columns if col_name != &#34;_sourceFile&#34;]
        )
        return specimen_df

    def map_centre_ids(self, dcc_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Maps the center ids  found in the XML files to a standard list of ids e.g:
            - gmc -&gt; HMGU
            - h -&gt; MRC Harwell
        The full list of mappings can be found at `impc_etl.config.Constants.CENTRE_ID_MAP`
        &#34;&#34;&#34;
        dcc_df = dcc_df.withColumn(
            &#34;_centreID&#34;, udf(utils.map_centre_id, StringType())(&#34;_centreID&#34;)
        )
        return dcc_df

    def map_project_ids(self, dcc_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Maps the center ids  found in the XML files to a standard list of ids e.g:
            - dtcc -&gt; DTCC
            - riken brc -&gt; RBRC
        The full list of mappings can be found at `impc_etl.config.Constants.PROJECT_ID_MAP`
        &#34;&#34;&#34;
        dcc_df = dcc_df.withColumn(
            &#34;_project&#34;, udf(utils.map_project_id, StringType())(&#34;_project&#34;)
        )
        return dcc_df

    def map_production_centre_ids(self, dcc_experiment_df: DataFrame):
        &#34;&#34;&#34;
        Maps the center ids  found in the XML files to a standard list of ids e.g:
            - gmc -&gt; HMGU
            - h -&gt; MRC Harwell
        The full list of mappings can be found at `impc_etl.config.Constants.CENTRE_ID_MAP`
        &#34;&#34;&#34;
        if &#34;_productionCentre&#34; not in dcc_experiment_df.columns:
            dcc_experiment_df = dcc_experiment_df.withColumn(
                &#34;_productionCentre&#34;, lit(None)
            )
        dcc_experiment_df = dcc_experiment_df.withColumn(
            &#34;_productionCentre&#34;,
            udf(utils.map_centre_id, StringType())(&#34;_productionCentre&#34;),
        )
        return dcc_experiment_df

    def map_phenotyping_centre_ids(self, dcc_experiment_df: DataFrame):
        &#34;&#34;&#34;
        Maps the center ids  found in the XML files to a standard list of ids e.g:
            - gmc -&gt; HMGU
            - h -&gt; MRC Harwell
        The full list of mappings can be found at `impc_etl.config.Constants.CENTRE_ID_MAP`
        &#34;&#34;&#34;
        dcc_experiment_df = dcc_experiment_df.withColumn(
            &#34;_phenotypingCentre&#34;,
            udf(utils.map_centre_id, StringType())(&#34;_phenotypingCentre&#34;),
        )
        return dcc_experiment_df

    def truncate_europhenome_specimen_ids(self, dcc_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Some EuroPhenome Specimen Ids have a suffix that should be truncated, the legacy identifying strategy for Specimen id included
        a suffix tno reference the production/phenotyping Centre (e.g. 232328312_HRW), that suffix needs to be removed.
        &#34;&#34;&#34;
        dcc_df = dcc_df.withColumn(
            &#34;_specimenID&#34;,
            when(
                dcc_df[&#34;_dataSource&#34;].isin([&#34;europhenome&#34;, &#34;MGP&#34;]),
                udf(utils.truncate_specimen_id, StringType())(dcc_df[&#34;_specimenID&#34;]),
            ).otherwise(dcc_df[&#34;_specimenID&#34;]),
        )
        return dcc_df

    def truncate_europhenome_colony_ids(self, dcc_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Some EuroPhenome Colony Ids have a suffix that should be truncated. Same as Specimen IDs some colony IDs used to have a suffix to identify
        the Centre and that has been  removed from the
        tracking system, so we need to truncate them so they  match the corresponding  entry on GenTar.
        &#34;&#34;&#34;
        dcc_df = dcc_df.withColumn(
            &#34;_colonyID&#34;,
            when(
                dcc_df[&#34;_dataSource&#34;] == &#34;europhenome&#34;,
                udf(utils.truncate_colony_id, StringType())(dcc_df[&#34;_colonyID&#34;]),
            ).otherwise(dcc_df[&#34;_colonyID&#34;]),
        )
        return dcc_df

    def parse_europhenome_colony_xml_entities(self, dcc_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Some EuroPhenome Colony Ids have &amp;lt; &amp;gt; values that have to be replaced by the  corresponding characters &lt; and &gt;.
        &#34;&#34;&#34;
        dcc_df = dcc_df.withColumn(
            &#34;_colonyID&#34;,
            when(
                (dcc_df[&#34;_dataSource&#34;] == &#34;europhenome&#34;),
                regexp_replace(&#34;_colonyID&#34;, &#34;&amp;lt;&#34;, &#34;&lt;&#34;),
            ).otherwise(dcc_df[&#34;_colonyID&#34;]),
        )

        dcc_df = dcc_df.withColumn(
            &#34;_colonyID&#34;,
            when(
                (dcc_df[&#34;_dataSource&#34;] == &#34;europhenome&#34;),
                regexp_replace(&#34;_colonyID&#34;, &#34;&amp;gt;&#34;, &#34;&gt;&#34;),
            ).otherwise(dcc_df[&#34;_colonyID&#34;]),
        )
        return dcc_df

    def standardize_strain_ids(self, dcc_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Some strain IDs are provided as MGI identifiers and some others don&#39;t, some of the ones provided as MGI identifiers lack the  &#39;MGI:&#39;,
        here we remove the &#39;MGI:&#39; from al of them to be able to process them in a consistent way in future tasks.
        &#34;&#34;&#34;
        dcc_df = dcc_df.withColumn(
            &#34;_strainID&#34;, regexp_replace(dcc_df[&#34;_strainID&#34;], &#34;MGI:&#34;, &#34;&#34;)
        )
        return dcc_df

    def override_3i_specimen_data(self, dcc_specimen_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Whenever a Specime is presetn both in the 3i project and any other data source (e.g. EuroPhenome or IMPC) the other data source specimen data should be used instead of the 3i one.
        &#34;&#34;&#34;
        dcc_specimen_df_a = dcc_specimen_df.alias(&#34;a&#34;)
        dcc_specimen_df_b = dcc_specimen_df.alias(&#34;b&#34;)
        dcc_specimen_df = dcc_specimen_df_a.join(
            dcc_specimen_df_b,
            (dcc_specimen_df_a[&#34;_specimenID&#34;] == dcc_specimen_df_b[&#34;_specimenID&#34;])
            &amp; (dcc_specimen_df_a[&#34;_centreID&#34;] == dcc_specimen_df_b[&#34;_centreID&#34;])
            &amp; (dcc_specimen_df_a[&#34;_dataSource&#34;] != dcc_specimen_df_b[&#34;_dataSource&#34;]),
            &#34;left_outer&#34;,
        )
        dcc_specimen_df = dcc_specimen_df.where(
            col(&#34;b._specimenID&#34;).isNull()
            | ((col(&#34;b._specimenID&#34;).isNotNull()) &amp; (col(&#34;a._dataSource&#34;) != &#34;3i&#34;))
        )
        return dcc_specimen_df.select(&#34;a.*&#34;).dropDuplicates()

    def generate_unique_id(self, dcc_specimen_df: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Generates an unique identifier for the  Specimen using productin centre, phenotyping centre  and specimen ID.
        &#34;&#34;&#34;
        dcc_specimen_df = dcc_specimen_df.withColumn(
            &#34;unique_id&#34;,
            md5(
                concat(
                    *[
                        when(
                            col(&#34;_productionCentre&#34;).isNotNull(),
                            col(&#34;_productionCentre&#34;),
                        )
                        .when(
                            col(&#34;_phenotypingCentre&#34;).isNotNull(),
                            col(&#34;_phenotypingCentre&#34;),
                        )
                        .otherwise(lit(&#34;&#34;)),
                        col(&#34;_specimenID&#34;),
                    ]
                )
            ),
        )
        return dcc_specimen_df</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>luigi.contrib.spark.PySparkTask</li>
<li>luigi.contrib.spark.SparkSubmitTask</li>
<li>luigi.contrib.external_program.ExternalProgramTask</li>
<li>luigi.task.Task</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="impc_etl.workflow.cleaning.EmbryoCleaner" href="../../workflow/cleaning.html#impc_etl.workflow.cleaning.EmbryoCleaner">EmbryoCleaner</a></li>
<li><a title="impc_etl.workflow.cleaning.MouseCleaner" href="../../workflow/cleaning.html#impc_etl.workflow.cleaning.MouseCleaner">MouseCleaner</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.name"><code class="name">var <span class="ident">name</span> : str</code></dt>
<dd>
<div class="desc"><p>Name of the Spark task</p></div>
</dd>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.output_path"><code class="name">var <span class="ident">output_path</span> : luigi.parameter.Parameter</code></dt>
<dd>
<div class="desc"><p>Path of the output directory where the new parquet file will be generated.</p></div>
</dd>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.specimen_type"><code class="name">var <span class="ident">specimen_type</span> : luigi.parameter.Parameter</code></dt>
<dd>
<div class="desc"><p>Specimen type can be 'mouse' or 'embryo'</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.app_options"><code class="name flex">
<span>def <span class="ident">app_options</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates the options pass to the PySpark job</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def app_options(self):
    &#34;&#34;&#34;
    Generates the options pass to the PySpark job
    &#34;&#34;&#34;
    return [
        self.input().path,
        self.output().path,
    ]</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.clean_specimens"><code class="name flex">
<span>def <span class="ident">clean_specimens</span></span>(<span>self, specimen_df: pyspark.sql.dataframe.DataFrame) ‑> pyspark.sql.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>DCC specimen cleaner
:return: a clean specimen parquet file
:rtype: DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_specimens(self, specimen_df: DataFrame) -&gt; DataFrame:
    &#34;&#34;&#34;
    DCC specimen cleaner
    :return: a clean specimen parquet file
    :rtype: DataFrame
    &#34;&#34;&#34;
    specimen_df: DataFrame = (
        specimen_df.transform(self.map_centre_ids)
        .transform(self.map_project_ids)
        .transform(self.map_production_centre_ids)
        .transform(self.map_phenotyping_centre_ids)
    )

    specimen_df = specimen_df.transform(self.truncate_europhenome_specimen_ids)
    specimen_df = specimen_df.transform(self.truncate_europhenome_colony_ids)
    specimen_df = specimen_df.transform(self.parse_europhenome_colony_xml_entities)
    specimen_df = specimen_df.transform(self.standardize_strain_ids)
    specimen_df = specimen_df.transform(self.override_3i_specimen_data)
    specimen_df = specimen_df.transform(self.generate_unique_id)

    # Some specimen can be found several times in the XML file submitted by the IMPC
    # So it is necessary to drop the duplicates
    specimen_df = specimen_df.drop_duplicates(
        [col_name for col_name in specimen_df.columns if col_name != &#34;_sourceFile&#34;]
    )
    return specimen_df</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.generate_unique_id"><code class="name flex">
<span>def <span class="ident">generate_unique_id</span></span>(<span>self, dcc_specimen_df: pyspark.sql.dataframe.DataFrame) ‑> pyspark.sql.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Generates an unique identifier for the
Specimen using productin centre, phenotyping centre
and specimen ID.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_unique_id(self, dcc_specimen_df: DataFrame) -&gt; DataFrame:
    &#34;&#34;&#34;
    Generates an unique identifier for the  Specimen using productin centre, phenotyping centre  and specimen ID.
    &#34;&#34;&#34;
    dcc_specimen_df = dcc_specimen_df.withColumn(
        &#34;unique_id&#34;,
        md5(
            concat(
                *[
                    when(
                        col(&#34;_productionCentre&#34;).isNotNull(),
                        col(&#34;_productionCentre&#34;),
                    )
                    .when(
                        col(&#34;_phenotypingCentre&#34;).isNotNull(),
                        col(&#34;_phenotypingCentre&#34;),
                    )
                    .otherwise(lit(&#34;&#34;)),
                    col(&#34;_specimenID&#34;),
                ]
            )
        ),
    )
    return dcc_specimen_df</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>self, sc: pyspark.context.SparkContext, *args: Any)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads the given Specimen parquet and applies some data sanitizing functions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main(self, sc: SparkContext, *args: Any):
    &#34;&#34;&#34;
    Loads the given Specimen parquet and applies some data sanitizing functions.
    &#34;&#34;&#34;
    input_path = args[0]
    output_path = args[1]
    spark_session = SparkSession.builder.getOrCreate()
    specimen_df = spark_session.read.parquet(input_path)
    specimen_clean_df = self.clean_specimens(specimen_df)
    specimen_clean_df = specimen_clean_df.dropDuplicates(
        [&#34;_specimenID&#34;, &#34;_centreID&#34;]
    )
    specimen_clean_df.write.mode(&#34;overwrite&#34;).parquet(output_path)</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.map_centre_ids"><code class="name flex">
<span>def <span class="ident">map_centre_ids</span></span>(<span>self, dcc_df: pyspark.sql.dataframe.DataFrame) ‑> pyspark.sql.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Maps the center ids
found in the XML files to a standard list of ids e.g:
- gmc -&gt; HMGU
- h -&gt; MRC Harwell
The full list of mappings can be found at <code>impc_etl.config.Constants.CENTRE_ID_MAP</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def map_centre_ids(self, dcc_df: DataFrame) -&gt; DataFrame:
    &#34;&#34;&#34;
    Maps the center ids  found in the XML files to a standard list of ids e.g:
        - gmc -&gt; HMGU
        - h -&gt; MRC Harwell
    The full list of mappings can be found at `impc_etl.config.Constants.CENTRE_ID_MAP`
    &#34;&#34;&#34;
    dcc_df = dcc_df.withColumn(
        &#34;_centreID&#34;, udf(utils.map_centre_id, StringType())(&#34;_centreID&#34;)
    )
    return dcc_df</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.map_phenotyping_centre_ids"><code class="name flex">
<span>def <span class="ident">map_phenotyping_centre_ids</span></span>(<span>self, dcc_experiment_df: pyspark.sql.dataframe.DataFrame)</span>
</code></dt>
<dd>
<div class="desc"><p>Maps the center ids
found in the XML files to a standard list of ids e.g:
- gmc -&gt; HMGU
- h -&gt; MRC Harwell
The full list of mappings can be found at <code>impc_etl.config.Constants.CENTRE_ID_MAP</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def map_phenotyping_centre_ids(self, dcc_experiment_df: DataFrame):
    &#34;&#34;&#34;
    Maps the center ids  found in the XML files to a standard list of ids e.g:
        - gmc -&gt; HMGU
        - h -&gt; MRC Harwell
    The full list of mappings can be found at `impc_etl.config.Constants.CENTRE_ID_MAP`
    &#34;&#34;&#34;
    dcc_experiment_df = dcc_experiment_df.withColumn(
        &#34;_phenotypingCentre&#34;,
        udf(utils.map_centre_id, StringType())(&#34;_phenotypingCentre&#34;),
    )
    return dcc_experiment_df</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.map_production_centre_ids"><code class="name flex">
<span>def <span class="ident">map_production_centre_ids</span></span>(<span>self, dcc_experiment_df: pyspark.sql.dataframe.DataFrame)</span>
</code></dt>
<dd>
<div class="desc"><p>Maps the center ids
found in the XML files to a standard list of ids e.g:
- gmc -&gt; HMGU
- h -&gt; MRC Harwell
The full list of mappings can be found at <code>impc_etl.config.Constants.CENTRE_ID_MAP</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def map_production_centre_ids(self, dcc_experiment_df: DataFrame):
    &#34;&#34;&#34;
    Maps the center ids  found in the XML files to a standard list of ids e.g:
        - gmc -&gt; HMGU
        - h -&gt; MRC Harwell
    The full list of mappings can be found at `impc_etl.config.Constants.CENTRE_ID_MAP`
    &#34;&#34;&#34;
    if &#34;_productionCentre&#34; not in dcc_experiment_df.columns:
        dcc_experiment_df = dcc_experiment_df.withColumn(
            &#34;_productionCentre&#34;, lit(None)
        )
    dcc_experiment_df = dcc_experiment_df.withColumn(
        &#34;_productionCentre&#34;,
        udf(utils.map_centre_id, StringType())(&#34;_productionCentre&#34;),
    )
    return dcc_experiment_df</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.map_project_ids"><code class="name flex">
<span>def <span class="ident">map_project_ids</span></span>(<span>self, dcc_df: pyspark.sql.dataframe.DataFrame) ‑> pyspark.sql.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Maps the center ids
found in the XML files to a standard list of ids e.g:
- dtcc -&gt; DTCC
- riken brc -&gt; RBRC
The full list of mappings can be found at <code>impc_etl.config.Constants.PROJECT_ID_MAP</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def map_project_ids(self, dcc_df: DataFrame) -&gt; DataFrame:
    &#34;&#34;&#34;
    Maps the center ids  found in the XML files to a standard list of ids e.g:
        - dtcc -&gt; DTCC
        - riken brc -&gt; RBRC
    The full list of mappings can be found at `impc_etl.config.Constants.PROJECT_ID_MAP`
    &#34;&#34;&#34;
    dcc_df = dcc_df.withColumn(
        &#34;_project&#34;, udf(utils.map_project_id, StringType())(&#34;_project&#34;)
    )
    return dcc_df</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.output"><code class="name flex">
<span>def <span class="ident">output</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the full parquet path as an output for the Luigi Task
(e.g. impc/dr15.2/parquet/mouse_specimen_clean_parquet)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def output(self):
    &#34;&#34;&#34;
    Returns the full parquet path as an output for the Luigi Task
    (e.g. impc/dr15.2/parquet/mouse_specimen_clean_parquet)
    &#34;&#34;&#34;
    return ImpcConfig().get_target(
        f&#34;{self.output_path}{self.specimen_type}_specimen_clean_parquet&#34;
    )</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.override_3i_specimen_data"><code class="name flex">
<span>def <span class="ident">override_3i_specimen_data</span></span>(<span>self, dcc_specimen_df: pyspark.sql.dataframe.DataFrame) ‑> pyspark.sql.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Whenever a Specime is presetn both in the 3i project and any other data source (e.g. EuroPhenome or IMPC) the other data source specimen data should be used instead of the 3i one.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def override_3i_specimen_data(self, dcc_specimen_df: DataFrame) -&gt; DataFrame:
    &#34;&#34;&#34;
    Whenever a Specime is presetn both in the 3i project and any other data source (e.g. EuroPhenome or IMPC) the other data source specimen data should be used instead of the 3i one.
    &#34;&#34;&#34;
    dcc_specimen_df_a = dcc_specimen_df.alias(&#34;a&#34;)
    dcc_specimen_df_b = dcc_specimen_df.alias(&#34;b&#34;)
    dcc_specimen_df = dcc_specimen_df_a.join(
        dcc_specimen_df_b,
        (dcc_specimen_df_a[&#34;_specimenID&#34;] == dcc_specimen_df_b[&#34;_specimenID&#34;])
        &amp; (dcc_specimen_df_a[&#34;_centreID&#34;] == dcc_specimen_df_b[&#34;_centreID&#34;])
        &amp; (dcc_specimen_df_a[&#34;_dataSource&#34;] != dcc_specimen_df_b[&#34;_dataSource&#34;]),
        &#34;left_outer&#34;,
    )
    dcc_specimen_df = dcc_specimen_df.where(
        col(&#34;b._specimenID&#34;).isNull()
        | ((col(&#34;b._specimenID&#34;).isNotNull()) &amp; (col(&#34;a._dataSource&#34;) != &#34;3i&#34;))
    )
    return dcc_specimen_df.select(&#34;a.*&#34;).dropDuplicates()</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.parse_europhenome_colony_xml_entities"><code class="name flex">
<span>def <span class="ident">parse_europhenome_colony_xml_entities</span></span>(<span>self, dcc_df: pyspark.sql.dataframe.DataFrame) ‑> pyspark.sql.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Some EuroPhenome Colony Ids have &lt; &gt; values that have to be replaced by the
corresponding characters &lt; and &gt;.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_europhenome_colony_xml_entities(self, dcc_df: DataFrame) -&gt; DataFrame:
    &#34;&#34;&#34;
    Some EuroPhenome Colony Ids have &amp;lt; &amp;gt; values that have to be replaced by the  corresponding characters &lt; and &gt;.
    &#34;&#34;&#34;
    dcc_df = dcc_df.withColumn(
        &#34;_colonyID&#34;,
        when(
            (dcc_df[&#34;_dataSource&#34;] == &#34;europhenome&#34;),
            regexp_replace(&#34;_colonyID&#34;, &#34;&amp;lt;&#34;, &#34;&lt;&#34;),
        ).otherwise(dcc_df[&#34;_colonyID&#34;]),
    )

    dcc_df = dcc_df.withColumn(
        &#34;_colonyID&#34;,
        when(
            (dcc_df[&#34;_dataSource&#34;] == &#34;europhenome&#34;),
            regexp_replace(&#34;_colonyID&#34;, &#34;&amp;gt;&#34;, &#34;&gt;&#34;),
        ).otherwise(dcc_df[&#34;_colonyID&#34;]),
    )
    return dcc_df</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.requires"><code class="name flex">
<span>def <span class="ident">requires</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the luigi
task dependencies</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def requires(self):
    &#34;&#34;&#34;
    Defines the luigi  task dependencies
    &#34;&#34;&#34;
    return (
        MouseSpecimenExtractor()
        if self.specimen_type == &#34;mouse&#34;
        else EmbryoSpecimenExtractor()
    )</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.standardize_strain_ids"><code class="name flex">
<span>def <span class="ident">standardize_strain_ids</span></span>(<span>self, dcc_df: pyspark.sql.dataframe.DataFrame) ‑> pyspark.sql.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Some strain IDs are provided as MGI identifiers and some others don't, some of the ones provided as MGI identifiers lack the
'MGI:',
here we remove the 'MGI:' from al of them to be able to process them in a consistent way in future tasks.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def standardize_strain_ids(self, dcc_df: DataFrame) -&gt; DataFrame:
    &#34;&#34;&#34;
    Some strain IDs are provided as MGI identifiers and some others don&#39;t, some of the ones provided as MGI identifiers lack the  &#39;MGI:&#39;,
    here we remove the &#39;MGI:&#39; from al of them to be able to process them in a consistent way in future tasks.
    &#34;&#34;&#34;
    dcc_df = dcc_df.withColumn(
        &#34;_strainID&#34;, regexp_replace(dcc_df[&#34;_strainID&#34;], &#34;MGI:&#34;, &#34;&#34;)
    )
    return dcc_df</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.truncate_europhenome_colony_ids"><code class="name flex">
<span>def <span class="ident">truncate_europhenome_colony_ids</span></span>(<span>self, dcc_df: pyspark.sql.dataframe.DataFrame) ‑> pyspark.sql.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Some EuroPhenome Colony Ids have a suffix that should be truncated. Same as Specimen IDs some colony IDs used to have a suffix to identify
the Centre and that has been
removed from the
tracking system, so we need to truncate them so they
match the corresponding
entry on GenTar.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def truncate_europhenome_colony_ids(self, dcc_df: DataFrame) -&gt; DataFrame:
    &#34;&#34;&#34;
    Some EuroPhenome Colony Ids have a suffix that should be truncated. Same as Specimen IDs some colony IDs used to have a suffix to identify
    the Centre and that has been  removed from the
    tracking system, so we need to truncate them so they  match the corresponding  entry on GenTar.
    &#34;&#34;&#34;
    dcc_df = dcc_df.withColumn(
        &#34;_colonyID&#34;,
        when(
            dcc_df[&#34;_dataSource&#34;] == &#34;europhenome&#34;,
            udf(utils.truncate_colony_id, StringType())(dcc_df[&#34;_colonyID&#34;]),
        ).otherwise(dcc_df[&#34;_colonyID&#34;]),
    )
    return dcc_df</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.truncate_europhenome_specimen_ids"><code class="name flex">
<span>def <span class="ident">truncate_europhenome_specimen_ids</span></span>(<span>self, dcc_df: pyspark.sql.dataframe.DataFrame) ‑> pyspark.sql.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Some EuroPhenome Specimen Ids have a suffix that should be truncated, the legacy identifying strategy for Specimen id included
a suffix tno reference the production/phenotyping Centre (e.g. 232328312_HRW), that suffix needs to be removed.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def truncate_europhenome_specimen_ids(self, dcc_df: DataFrame) -&gt; DataFrame:
    &#34;&#34;&#34;
    Some EuroPhenome Specimen Ids have a suffix that should be truncated, the legacy identifying strategy for Specimen id included
    a suffix tno reference the production/phenotyping Centre (e.g. 232328312_HRW), that suffix needs to be removed.
    &#34;&#34;&#34;
    dcc_df = dcc_df.withColumn(
        &#34;_specimenID&#34;,
        when(
            dcc_df[&#34;_dataSource&#34;].isin([&#34;europhenome&#34;, &#34;MGP&#34;]),
            udf(utils.truncate_specimen_id, StringType())(dcc_df[&#34;_specimenID&#34;]),
        ).otherwise(dcc_df[&#34;_specimenID&#34;]),
    )
    return dcc_df</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<div style="max-width: 300px; text-align: center">
<img src="https://www.mousephenotype.org/wp-content/themes/impc/images/IMPC_10_YEAR_Logo.svg" alt="IMPC Logo">
</div>
<h1 style="text-align: center; max-width: 300px;">IMPC ETL</h1>
<h2 style="text-align: center; max-width: 300px;">Reference Documentation</h2>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="impc_etl.jobs.clean" href="index.html">impc_etl.jobs.clean</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner">IMPCSpecimenCleaner</a></code></h4>
<ul class="">
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.app_options" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.app_options">app_options</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.clean_specimens" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.clean_specimens">clean_specimens</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.generate_unique_id" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.generate_unique_id">generate_unique_id</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.main" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.main">main</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.map_centre_ids" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.map_centre_ids">map_centre_ids</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.map_phenotyping_centre_ids" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.map_phenotyping_centre_ids">map_phenotyping_centre_ids</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.map_production_centre_ids" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.map_production_centre_ids">map_production_centre_ids</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.map_project_ids" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.map_project_ids">map_project_ids</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.name" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.name">name</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.output" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.output">output</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.output_path" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.output_path">output_path</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.override_3i_specimen_data" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.override_3i_specimen_data">override_3i_specimen_data</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.parse_europhenome_colony_xml_entities" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.parse_europhenome_colony_xml_entities">parse_europhenome_colony_xml_entities</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.requires" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.requires">requires</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.specimen_type" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.specimen_type">specimen_type</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.standardize_strain_ids" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.standardize_strain_ids">standardize_strain_ids</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.truncate_europhenome_colony_ids" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.truncate_europhenome_colony_ids">truncate_europhenome_colony_ids</a></code></li>
<li><code><a title="impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.truncate_europhenome_specimen_ids" href="#impc_etl.jobs.clean.specimen_cleaner.IMPCSpecimenCleaner.truncate_europhenome_specimen_ids">truncate_europhenome_specimen_ids</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p><span></span></p>
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>