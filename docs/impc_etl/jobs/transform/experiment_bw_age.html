<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>impc_etl.jobs.transform.experiment_bw_age API documentation</title>
<meta name="description" content="Luigi PySpark task to process experiments in order to calculate the age of the
specimen and the associated BW information for a given data point." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>impc_etl.jobs.transform.experiment_bw_age</code></h1>
</header>
<section id="section-intro">
<p>Luigi PySpark task to process experiments in order to calculate the age of the
specimen and the associated BW information for a given data point.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
    Luigi PySpark task to process experiments in order to calculate the age of the
    specimen and the associated BW information for a given data point.
&#34;&#34;&#34;
import math
from datetime import datetime
from typing import List, Dict

import luigi
from luigi.contrib.spark import PySparkTask
from pyspark.sql import SparkSession, DataFrame
from pyspark.sql.functions import (
    explode_outer,
    col,
    datediff,
    collect_set,
    struct,
    udf,
    when,
    expr,
    regexp_extract,
)
from pyspark.sql.types import (
    ArrayType,
    StructType,
    StructField,
    IntegerType,
    StringType,
    Row,
    DateType,
)

from impc_etl.jobs.extract import ImpressExtractor
from impc_etl.jobs.transform.experiment_parameter_derivator import (
    ExperimentParameterDerivator,
)
from impc_etl.shared.utils import (
    unix_time_millis,
)
from impc_etl.workflow.config import ImpcConfig
from impc_etl.workflow.normalization import (
    MouseNormalizer,
)


class ExperimentBWAgeProcessor(PySparkTask):
    &#34;&#34;&#34;
    PysPark task to process determine AGE of Specimen and BW data associations for a given experiment.
    This task depends on `impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator`,
    `impc_etl.workflow.normalization.MouseNormalizer` and `impc_etl.jobs.extract.impress_extractor.ImpressExtractor`.
    &#34;&#34;&#34;

    #: Name of the Spark task
    name = &#34;IMPC_Experiment_ADD_BW_AGE_Processor&#34;

    #: Path of the output directory where the new parquet file will be generated.
    output_path = luigi.Parameter()

    def requires(self):
        &#34;&#34;&#34;
        Defines the luigi  task dependencies
        &#34;&#34;&#34;
        return [ExperimentParameterDerivator(), MouseNormalizer(), ImpressExtractor()]

    def output(self):
        &#34;&#34;&#34;
        Returns the full parquet path as an output for the Luigi Task
        (e.g. impc/dr15.2/parquet/experiment_with_bw_age_parquet)
        &#34;&#34;&#34;
        return ImpcConfig().get_target(
            f&#34;{self.output_path}experiment_with_bw_age_parquet&#34;
        )

    def app_options(self):
        &#34;&#34;&#34;
        Generates the options pass to the PySpark job
        &#34;&#34;&#34;
        return [
            self.input()[0].path,
            self.input()[1].path,
            self.input()[2].path,
            self.output().path,
        ]

    def main(self, sc, *args):
        &#34;&#34;&#34;
        Loads the given the Experiment parquet, the Specimen parquet and the Impress parquet,
        and uses them to calculate the age of the specimen at any given experiment date and to associate
        BW data to every experiment when possible.
        &#34;&#34;&#34;
        spark = SparkSession(sc)
        spark.sql(&#34;set spark.sql.legacy.timeParserPolicy=LEGACY&#34;)
        spark.sql(&#34;set spark.sql.legacy.parquet.datetimeRebaseModeInWrite=LEGACY&#34;)
        experiment_parquet_path = args[0]
        mouse_parquet_path = args[1]
        pipeline_parquet_path = args[2]
        output_path = args[3]
        experiment_df = spark.read.parquet(experiment_parquet_path)
        mouse_df = spark.read.parquet(mouse_parquet_path)
        pipeline_df = spark.read.parquet(pipeline_parquet_path)
        experiment_df = self.get_associated_body_weight(
            experiment_df, mouse_df, pipeline_df
        )
        experiment_df = self.generate_age_information(experiment_df, mouse_df)
        experiment_df.write.parquet(output_path)

    def get_associated_body_weight(
        self,
        specimen_level_experiment_df: DataFrame,
        mouse_specimen_df: DataFrame,
        impress_df: DataFrame,
    ) -&gt; DataFrame:
        &#34;&#34;&#34;
        Takes in DataFrame with Experimental data, one with Mouse Specimens and one with Impress information,
        and applies the algorithm to select the associated BW to any given experiment
        and calculate the age of experiment for the selected BW measurement.
        &#34;&#34;&#34;
        # Explode the nested experiment DF structure so every row represents an observation
        weight_observations: DataFrame = specimen_level_experiment_df.withColumn(
            &#34;simpleParameter&#34;, explode_outer(&#34;simpleParameter&#34;)
        )

        # Select the parameter relevant pieces from the IMPReSS DF
        parameters = impress_df.select(
            &#34;pipelineKey&#34;,
            &#34;procedure.procedureKey&#34;,
            &#34;parameter.parameterKey&#34;,
            &#34;parameter.analysisWithBodyweight&#34;,
        ).distinct()

        # Filter the IMPReSS using the analysisWithBodyweight flag
        weight_parameters = parameters.where(
            col(&#34;analysisWithBodyweight&#34;).isin(
                [&#34;is_body_weight&#34;, &#34;is_fasted_body_weight&#34;]
            )
        )

        # Join both the  observations DF and the BW parameters DF to obtain the observations that are BW
        weight_observations = weight_observations.join(
            weight_parameters,
            (
                (weight_observations[&#34;_pipeline&#34;] == weight_parameters[&#34;pipelineKey&#34;])
                &amp; (
                    weight_observations[&#34;_procedureID&#34;]
                    == weight_parameters[&#34;procedureKey&#34;]
                )
                &amp; (
                    weight_observations[&#34;simpleParameter._parameterID&#34;]
                    == weight_parameters[&#34;parameterKey&#34;]
                )
            ),
        )
        # Create a boolean flag for fasted BW procedures
        weight_observations = weight_observations.withColumn(
            &#34;weightFasted&#34;, col(&#34;analysisWithBodyweight&#34;) == &#34;is_fasted_body_weight&#34;
        )

        weight_observations = weight_observations.select(
            &#34;specimenID&#34;,
            &#34;_centreID&#34;,
            col(&#34;unique_id&#34;).alias(&#34;sourceExperimentId&#34;),
            col(&#34;_dateOfExperiment&#34;).alias(&#34;weightDate&#34;),
            col(&#34;simpleParameter._parameterID&#34;).alias(&#34;weightParameterID&#34;),
            col(&#34;simpleParameter.value&#34;).alias(&#34;weightValue&#34;),
            &#34;weightFasted&#34;,
        )
        weight_observations = weight_observations.where(col(&#34;weightValue&#34;).isNotNull())

        # Join the body weight observations so we can determine the  age of the specimen for any BW measurement
        weight_observations = weight_observations.join(
            mouse_specimen_df,
            (weight_observations[&#34;specimenID&#34;] == mouse_specimen_df[&#34;_specimenID&#34;])
            &amp; (weight_observations[&#34;_centreID&#34;] == mouse_specimen_df[&#34;_centreID&#34;]),
        )
        weight_observations = weight_observations.withColumn(
            &#34;weightDaysOld&#34;, datediff(&#34;weightDate&#34;, &#34;_DOB&#34;)
        )

        #  Group the weight observations by Specimen
        weight_observations = weight_observations.groupBy(&#34;specimenID&#34;).agg(
            collect_set(
                struct(
                    &#34;sourceExperimentId&#34;,
                    &#34;weightDate&#34;,
                    &#34;weightParameterID&#34;,
                    &#34;weightValue&#34;,
                    &#34;weightDaysOld&#34;,
                    &#34;weightFasted&#34;,
                )
            ).alias(&#34;weight_observations&#34;)
        )

        # Create a temporary &#34;procedureGroup&#34; column to be used in the  BW selection
        specimen_level_experiment_df = specimen_level_experiment_df.withColumn(
            &#34;procedureGroup&#34;,
            udf(lambda prod_id: prod_id[: prod_id.rfind(&#34;_&#34;)], StringType())(
                col(&#34;_procedureID&#34;)
            ),
        )

        # Join all the observations with the BW observations grouped by specimen
        specimen_level_experiment_df = specimen_level_experiment_df.join(
            weight_observations, &#34;specimenID&#34;, &#34;left_outer&#34;
        )
        # Schema for the struct that is going to group all the associated BW data
        output_weight_schema = StructType(
            [
                StructField(&#34;sourceExperimentId&#34;, StringType()),
                StructField(&#34;weightDate&#34;, DateType()),
                StructField(&#34;weightParameterID&#34;, StringType()),
                StructField(&#34;weightValue&#34;, StringType()),
                StructField(&#34;weightDaysOld&#34;, IntegerType()),
                StructField(&#34;error&#34;, ArrayType(StringType())),
            ]
        )

        # Alias both the experiment and the specimen df so is easier to join and manipulate
        experiment_df_a = specimen_level_experiment_df.alias(&#34;exp&#34;)
        mice_df_a = mouse_specimen_df.alias(&#34;mice&#34;)

        specimen_level_experiment_df = experiment_df_a.join(
            mice_df_a,
            (
                specimen_level_experiment_df[&#34;specimenID&#34;]
                == mouse_specimen_df[&#34;_specimenID&#34;]
            )
            &amp; (
                specimen_level_experiment_df[&#34;_centreID&#34;]
                == mouse_specimen_df[&#34;_centreID&#34;]
            ),
            &#34;left_outer&#34;,
        )

        # Add special dates to the experiment x specimen dataframe
        # for some experiments the date of sacrifice or date of blood collection
        # has to be used as reference for age and  BW calculations
        specimen_level_experiment_df = self._add_special_dates(
            specimen_level_experiment_df
        )
        get_associated_body_weight_udf = udf(
            self._get_closest_weight, output_weight_schema
        )
        specimen_level_experiment_df = specimen_level_experiment_df.withColumn(
            &#34;weight&#34;,
            get_associated_body_weight_udf(
                when(
                    col(&#34;_dateOfBloodCollection&#34;).isNotNull(),
                    col(&#34;_dateOfBloodCollection&#34;),
                )
                .when(col(&#34;_dateOfSacrifice&#34;).isNotNull(), col(&#34;_dateOfSacrifice&#34;))
                .otherwise(col(&#34;_dateOfExperiment&#34;)),
                col(&#34;procedureGroup&#34;),
                col(&#34;weight_observations&#34;),
            ),
        )
        specimen_level_experiment_df = specimen_level_experiment_df.select(
            &#34;exp.*&#34;, &#34;weight&#34;
        )
        return specimen_level_experiment_df

    def generate_age_information(
        self, dcc_experiment_df: DataFrame, mice_df: DataFrame
    ):
        experiment_df_a = dcc_experiment_df.alias(&#34;exp&#34;)
        mice_df_a = mice_df.alias(&#34;mice&#34;)
        dcc_experiment_df = experiment_df_a.join(
            mice_df_a,
            (experiment_df_a[&#34;specimenID&#34;] == mice_df[&#34;_specimenID&#34;])
            &amp; (experiment_df_a[&#34;_centreID&#34;] == mice_df[&#34;_centreID&#34;]),
            &#34;left_outer&#34;,
        )
        dcc_experiment_df = self._add_special_dates(dcc_experiment_df)
        dcc_experiment_df = dcc_experiment_df.withColumn(
            &#34;ageInDays&#34;,
            datediff(
                when(
                    col(&#34;_dateOfBloodCollection&#34;).isNotNull(),
                    col(&#34;_dateOfBloodCollection&#34;),
                )
                .when(col(&#34;_dateOfSacrifice&#34;).isNotNull(), col(&#34;_dateOfSacrifice&#34;))
                .otherwise(col(&#34;_dateOfExperiment&#34;)),
                col(&#34;mice._DOB&#34;),
            ),
        )
        dcc_experiment_df = dcc_experiment_df.withColumn(
            &#34;ageInWeeks&#34;,
            udf(lambda x: math.floor(x / 7) if x is not None else None, IntegerType())(
                col(&#34;ageInDays&#34;)
            ),
        )
        return dcc_experiment_df.select(&#34;exp.*&#34;, &#34;ageInWeeks&#34;, &#34;ageInDays&#34;)

    def _get_closest_weight(
        self,
        experiment_date: datetime.date,
        procedure_group: str,
        specimen_weights: List[Row],
    ) -&gt; Dict:
        &#34;&#34;&#34;
        Takes in date of experiment, a procedure group, and a set of BW observations
        candidates and chooses the closest one.
        The algorithm first tries to get a BW that is on the same procedure group as the given experiment.
        It also takes into consideration if there is any fasted weight on the Specimen BW observations, if any,
        the whole BW observations set should be replaced with only
        the fasted BWs, this is because if the procedure has a fasted BW,
        this means any observation on the procedure should be associated with that
        fasted value instead of using any other, even when they are closer. After that it selects a list of candidate
        weights and tries to find the closest BW that belongs to the same procedure first. If it doesn&#39;t find any,
        it tries with BW observations coming from the _BWT procedures, if there is none _BWT procedure observations,
        it looks for any other procedures. Finally, the  algorithm limits the maximum distance for between the closest
        BW observation anf the experiment date to 5 days, if there is not suitable BW assocition in the 5 days window
        around the experiment date, the BW association is marked as null.
        &#34;&#34;&#34;
        if specimen_weights is None or len(specimen_weights) == 0:
            return {
                &#34;sourceExperimentId&#34;: None,
                &#34;weightDate&#34;: None,
                &#34;weightValue&#34;: None,
                &#34;weightParameterID&#34;: None,
                &#34;weightDaysOld&#34;: None,
            }
        nearest_weight = None
        nearest_diff = None
        errors = []
        min_time = datetime.min.time()
        experiment_date_time = datetime.combine(experiment_date, min_time)
        fasted_weights = [w for w in specimen_weights if w[&#34;weightFasted&#34;]]
        non_fasted_weights = [w for w in specimen_weights if not w[&#34;weightFasted&#34;]]
        if len(fasted_weights) &gt; 0:
            same_procedure_fasted_weights = [
                w for w in fasted_weights if procedure_group in w[&#34;weightParameterID&#34;]
            ]
            if len(same_procedure_fasted_weights) &gt; 0:
                specimen_weights = same_procedure_fasted_weights
            else:
                specimen_weights = non_fasted_weights
        for candidate_weight in specimen_weights:
            if (
                candidate_weight[&#34;weightValue&#34;] == &#34;null&#34;
                or candidate_weight[&#34;weightDate&#34;] == &#34;null&#34;
            ):
                continue
            candidate_weight_date = candidate_weight[&#34;weightDate&#34;]
            candidate_weight_time = datetime.combine(candidate_weight_date, min_time)
            # TODO: TypeError: unsupported operand type(s) for -: &#39;datetime.date&#39; and &#39;datetime.datetime&#39;
            candidate_diff = abs(
                unix_time_millis(experiment_date_time)
                - unix_time_millis(candidate_weight_time)
            )
            if nearest_weight is None:
                nearest_weight = candidate_weight
                nearest_diff = candidate_diff
                continue
            try:
                candidate_weight_value = float(candidate_weight[&#34;weightValue&#34;])
            except ValueError:
                errors.append(&#34;[PARSING] Failed to parse: &#34; + str(candidate_weight))
                continue

            try:
                nearest_weight_value = float(nearest_weight[&#34;weightValue&#34;])
            except ValueError:
                errors.append(
                    &#34;[PARSING] Failed to parse: &#34;
                    + str(nearest_weight[&#34;weightValue&#34;])
                    + &#34; &#34;
                    + procedure_group
                    + &#34; &#34;
                    + str(experiment_date)
                )
                continue

            if candidate_diff &lt; nearest_diff:
                nearest_weight = candidate_weight
                nearest_diff = candidate_diff
            elif candidate_diff == nearest_diff:
                if (
                    procedure_group is not None
                    and procedure_group in candidate_weight[&#34;weightParameterID&#34;]
                ):
                    if candidate_weight_value &gt; nearest_weight_value:
                        nearest_weight = candidate_weight
                        nearest_diff = candidate_diff
                elif &#34;_BWT&#34; in candidate_weight[&#34;weightParameterID&#34;]:
                    if candidate_weight_value &gt; nearest_weight_value:
                        nearest_weight = candidate_weight
                        nearest_diff = candidate_diff
                elif candidate_weight_value &gt; nearest_weight_value:
                    nearest_weight = candidate_weight
                    nearest_diff = candidate_diff

        days_diff = nearest_diff / 86400000 if nearest_diff is not None else 6

        if nearest_weight is not None and days_diff &lt; 5:
            return {**nearest_weight.asDict(), &#34;error&#34;: errors}
        else:
            return {
                &#34;sourceExperimentId&#34;: None,
                &#34;weightDate&#34;: None,
                &#34;weightValue&#34;: None,
                &#34;weightParameterID&#34;: None,
                &#34;weightDaysOld&#34;: None,
                &#34;error&#34;: errors,
            }

    def _add_special_dates(self, dcc_experiment_df: DataFrame):
        &#34;&#34;&#34;
        Takes in a DataFrame with experimental data, parses out the metadata values for special dates,
        and adds those values as new columns.
        &#34;&#34;&#34;
        for col_name, date_prefixes in {
            &#34;_dateOfBloodCollection&#34;: [
                &#34;date and time of blood collection = &#34;,
                &#34;date/time of blood collection = &#34;,
            ],
            &#34;_dateOfSacrifice&#34;: [
                &#34;date and time of sacrifice = &#34;,
                &#34;date of sacrifice = &#34;,
            ],
        }.items():
            escaped_prefixes = [prefix.replace(&#34;/&#34;, &#34;.&#34;) for prefix in date_prefixes]
            prefix_regex = f&#34;(?i)(.*)({&#39;|&#39;.join(escaped_prefixes)})(.*)&#34;
            dcc_experiment_df = dcc_experiment_df.withColumn(
                col_name + &#34;Array&#34;,
                expr(
                    f&#39;filter(metadata, metadataValue -&gt;  metadataValue rlike &#34;{prefix_regex}&#34; )&#39;
                ),
            )
            dcc_experiment_df = dcc_experiment_df.withColumn(
                col_name,
                regexp_extract(
                    col(col_name + &#34;Array&#34;).getItem(0), prefix_regex, 3
                ).astype(DateType()),
            )
        return dcc_experiment_df</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor"><code class="flex name class">
<span>class <span class="ident">ExperimentBWAgeProcessor</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>PysPark task to process determine AGE of Specimen and BW data associations for a given experiment.
This task depends on <code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator" href="experiment_parameter_derivator.html#impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator">ExperimentParameterDerivator</a></code>,
<code><a title="impc_etl.workflow.normalization.MouseNormalizer" href="../../workflow/normalization.html#impc_etl.workflow.normalization.MouseNormalizer">MouseNormalizer</a></code> and <code><a title="impc_etl.jobs.extract.impress_extractor.ImpressExtractor" href="../extract/impress_extractor.html#impc_etl.jobs.extract.impress_extractor.ImpressExtractor">ImpressExtractor</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ExperimentBWAgeProcessor(PySparkTask):
    &#34;&#34;&#34;
    PysPark task to process determine AGE of Specimen and BW data associations for a given experiment.
    This task depends on `impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator`,
    `impc_etl.workflow.normalization.MouseNormalizer` and `impc_etl.jobs.extract.impress_extractor.ImpressExtractor`.
    &#34;&#34;&#34;

    #: Name of the Spark task
    name = &#34;IMPC_Experiment_ADD_BW_AGE_Processor&#34;

    #: Path of the output directory where the new parquet file will be generated.
    output_path = luigi.Parameter()

    def requires(self):
        &#34;&#34;&#34;
        Defines the luigi  task dependencies
        &#34;&#34;&#34;
        return [ExperimentParameterDerivator(), MouseNormalizer(), ImpressExtractor()]

    def output(self):
        &#34;&#34;&#34;
        Returns the full parquet path as an output for the Luigi Task
        (e.g. impc/dr15.2/parquet/experiment_with_bw_age_parquet)
        &#34;&#34;&#34;
        return ImpcConfig().get_target(
            f&#34;{self.output_path}experiment_with_bw_age_parquet&#34;
        )

    def app_options(self):
        &#34;&#34;&#34;
        Generates the options pass to the PySpark job
        &#34;&#34;&#34;
        return [
            self.input()[0].path,
            self.input()[1].path,
            self.input()[2].path,
            self.output().path,
        ]

    def main(self, sc, *args):
        &#34;&#34;&#34;
        Loads the given the Experiment parquet, the Specimen parquet and the Impress parquet,
        and uses them to calculate the age of the specimen at any given experiment date and to associate
        BW data to every experiment when possible.
        &#34;&#34;&#34;
        spark = SparkSession(sc)
        spark.sql(&#34;set spark.sql.legacy.timeParserPolicy=LEGACY&#34;)
        spark.sql(&#34;set spark.sql.legacy.parquet.datetimeRebaseModeInWrite=LEGACY&#34;)
        experiment_parquet_path = args[0]
        mouse_parquet_path = args[1]
        pipeline_parquet_path = args[2]
        output_path = args[3]
        experiment_df = spark.read.parquet(experiment_parquet_path)
        mouse_df = spark.read.parquet(mouse_parquet_path)
        pipeline_df = spark.read.parquet(pipeline_parquet_path)
        experiment_df = self.get_associated_body_weight(
            experiment_df, mouse_df, pipeline_df
        )
        experiment_df = self.generate_age_information(experiment_df, mouse_df)
        experiment_df.write.parquet(output_path)

    def get_associated_body_weight(
        self,
        specimen_level_experiment_df: DataFrame,
        mouse_specimen_df: DataFrame,
        impress_df: DataFrame,
    ) -&gt; DataFrame:
        &#34;&#34;&#34;
        Takes in DataFrame with Experimental data, one with Mouse Specimens and one with Impress information,
        and applies the algorithm to select the associated BW to any given experiment
        and calculate the age of experiment for the selected BW measurement.
        &#34;&#34;&#34;
        # Explode the nested experiment DF structure so every row represents an observation
        weight_observations: DataFrame = specimen_level_experiment_df.withColumn(
            &#34;simpleParameter&#34;, explode_outer(&#34;simpleParameter&#34;)
        )

        # Select the parameter relevant pieces from the IMPReSS DF
        parameters = impress_df.select(
            &#34;pipelineKey&#34;,
            &#34;procedure.procedureKey&#34;,
            &#34;parameter.parameterKey&#34;,
            &#34;parameter.analysisWithBodyweight&#34;,
        ).distinct()

        # Filter the IMPReSS using the analysisWithBodyweight flag
        weight_parameters = parameters.where(
            col(&#34;analysisWithBodyweight&#34;).isin(
                [&#34;is_body_weight&#34;, &#34;is_fasted_body_weight&#34;]
            )
        )

        # Join both the  observations DF and the BW parameters DF to obtain the observations that are BW
        weight_observations = weight_observations.join(
            weight_parameters,
            (
                (weight_observations[&#34;_pipeline&#34;] == weight_parameters[&#34;pipelineKey&#34;])
                &amp; (
                    weight_observations[&#34;_procedureID&#34;]
                    == weight_parameters[&#34;procedureKey&#34;]
                )
                &amp; (
                    weight_observations[&#34;simpleParameter._parameterID&#34;]
                    == weight_parameters[&#34;parameterKey&#34;]
                )
            ),
        )
        # Create a boolean flag for fasted BW procedures
        weight_observations = weight_observations.withColumn(
            &#34;weightFasted&#34;, col(&#34;analysisWithBodyweight&#34;) == &#34;is_fasted_body_weight&#34;
        )

        weight_observations = weight_observations.select(
            &#34;specimenID&#34;,
            &#34;_centreID&#34;,
            col(&#34;unique_id&#34;).alias(&#34;sourceExperimentId&#34;),
            col(&#34;_dateOfExperiment&#34;).alias(&#34;weightDate&#34;),
            col(&#34;simpleParameter._parameterID&#34;).alias(&#34;weightParameterID&#34;),
            col(&#34;simpleParameter.value&#34;).alias(&#34;weightValue&#34;),
            &#34;weightFasted&#34;,
        )
        weight_observations = weight_observations.where(col(&#34;weightValue&#34;).isNotNull())

        # Join the body weight observations so we can determine the  age of the specimen for any BW measurement
        weight_observations = weight_observations.join(
            mouse_specimen_df,
            (weight_observations[&#34;specimenID&#34;] == mouse_specimen_df[&#34;_specimenID&#34;])
            &amp; (weight_observations[&#34;_centreID&#34;] == mouse_specimen_df[&#34;_centreID&#34;]),
        )
        weight_observations = weight_observations.withColumn(
            &#34;weightDaysOld&#34;, datediff(&#34;weightDate&#34;, &#34;_DOB&#34;)
        )

        #  Group the weight observations by Specimen
        weight_observations = weight_observations.groupBy(&#34;specimenID&#34;).agg(
            collect_set(
                struct(
                    &#34;sourceExperimentId&#34;,
                    &#34;weightDate&#34;,
                    &#34;weightParameterID&#34;,
                    &#34;weightValue&#34;,
                    &#34;weightDaysOld&#34;,
                    &#34;weightFasted&#34;,
                )
            ).alias(&#34;weight_observations&#34;)
        )

        # Create a temporary &#34;procedureGroup&#34; column to be used in the  BW selection
        specimen_level_experiment_df = specimen_level_experiment_df.withColumn(
            &#34;procedureGroup&#34;,
            udf(lambda prod_id: prod_id[: prod_id.rfind(&#34;_&#34;)], StringType())(
                col(&#34;_procedureID&#34;)
            ),
        )

        # Join all the observations with the BW observations grouped by specimen
        specimen_level_experiment_df = specimen_level_experiment_df.join(
            weight_observations, &#34;specimenID&#34;, &#34;left_outer&#34;
        )
        # Schema for the struct that is going to group all the associated BW data
        output_weight_schema = StructType(
            [
                StructField(&#34;sourceExperimentId&#34;, StringType()),
                StructField(&#34;weightDate&#34;, DateType()),
                StructField(&#34;weightParameterID&#34;, StringType()),
                StructField(&#34;weightValue&#34;, StringType()),
                StructField(&#34;weightDaysOld&#34;, IntegerType()),
                StructField(&#34;error&#34;, ArrayType(StringType())),
            ]
        )

        # Alias both the experiment and the specimen df so is easier to join and manipulate
        experiment_df_a = specimen_level_experiment_df.alias(&#34;exp&#34;)
        mice_df_a = mouse_specimen_df.alias(&#34;mice&#34;)

        specimen_level_experiment_df = experiment_df_a.join(
            mice_df_a,
            (
                specimen_level_experiment_df[&#34;specimenID&#34;]
                == mouse_specimen_df[&#34;_specimenID&#34;]
            )
            &amp; (
                specimen_level_experiment_df[&#34;_centreID&#34;]
                == mouse_specimen_df[&#34;_centreID&#34;]
            ),
            &#34;left_outer&#34;,
        )

        # Add special dates to the experiment x specimen dataframe
        # for some experiments the date of sacrifice or date of blood collection
        # has to be used as reference for age and  BW calculations
        specimen_level_experiment_df = self._add_special_dates(
            specimen_level_experiment_df
        )
        get_associated_body_weight_udf = udf(
            self._get_closest_weight, output_weight_schema
        )
        specimen_level_experiment_df = specimen_level_experiment_df.withColumn(
            &#34;weight&#34;,
            get_associated_body_weight_udf(
                when(
                    col(&#34;_dateOfBloodCollection&#34;).isNotNull(),
                    col(&#34;_dateOfBloodCollection&#34;),
                )
                .when(col(&#34;_dateOfSacrifice&#34;).isNotNull(), col(&#34;_dateOfSacrifice&#34;))
                .otherwise(col(&#34;_dateOfExperiment&#34;)),
                col(&#34;procedureGroup&#34;),
                col(&#34;weight_observations&#34;),
            ),
        )
        specimen_level_experiment_df = specimen_level_experiment_df.select(
            &#34;exp.*&#34;, &#34;weight&#34;
        )
        return specimen_level_experiment_df

    def generate_age_information(
        self, dcc_experiment_df: DataFrame, mice_df: DataFrame
    ):
        experiment_df_a = dcc_experiment_df.alias(&#34;exp&#34;)
        mice_df_a = mice_df.alias(&#34;mice&#34;)
        dcc_experiment_df = experiment_df_a.join(
            mice_df_a,
            (experiment_df_a[&#34;specimenID&#34;] == mice_df[&#34;_specimenID&#34;])
            &amp; (experiment_df_a[&#34;_centreID&#34;] == mice_df[&#34;_centreID&#34;]),
            &#34;left_outer&#34;,
        )
        dcc_experiment_df = self._add_special_dates(dcc_experiment_df)
        dcc_experiment_df = dcc_experiment_df.withColumn(
            &#34;ageInDays&#34;,
            datediff(
                when(
                    col(&#34;_dateOfBloodCollection&#34;).isNotNull(),
                    col(&#34;_dateOfBloodCollection&#34;),
                )
                .when(col(&#34;_dateOfSacrifice&#34;).isNotNull(), col(&#34;_dateOfSacrifice&#34;))
                .otherwise(col(&#34;_dateOfExperiment&#34;)),
                col(&#34;mice._DOB&#34;),
            ),
        )
        dcc_experiment_df = dcc_experiment_df.withColumn(
            &#34;ageInWeeks&#34;,
            udf(lambda x: math.floor(x / 7) if x is not None else None, IntegerType())(
                col(&#34;ageInDays&#34;)
            ),
        )
        return dcc_experiment_df.select(&#34;exp.*&#34;, &#34;ageInWeeks&#34;, &#34;ageInDays&#34;)

    def _get_closest_weight(
        self,
        experiment_date: datetime.date,
        procedure_group: str,
        specimen_weights: List[Row],
    ) -&gt; Dict:
        &#34;&#34;&#34;
        Takes in date of experiment, a procedure group, and a set of BW observations
        candidates and chooses the closest one.
        The algorithm first tries to get a BW that is on the same procedure group as the given experiment.
        It also takes into consideration if there is any fasted weight on the Specimen BW observations, if any,
        the whole BW observations set should be replaced with only
        the fasted BWs, this is because if the procedure has a fasted BW,
        this means any observation on the procedure should be associated with that
        fasted value instead of using any other, even when they are closer. After that it selects a list of candidate
        weights and tries to find the closest BW that belongs to the same procedure first. If it doesn&#39;t find any,
        it tries with BW observations coming from the _BWT procedures, if there is none _BWT procedure observations,
        it looks for any other procedures. Finally, the  algorithm limits the maximum distance for between the closest
        BW observation anf the experiment date to 5 days, if there is not suitable BW assocition in the 5 days window
        around the experiment date, the BW association is marked as null.
        &#34;&#34;&#34;
        if specimen_weights is None or len(specimen_weights) == 0:
            return {
                &#34;sourceExperimentId&#34;: None,
                &#34;weightDate&#34;: None,
                &#34;weightValue&#34;: None,
                &#34;weightParameterID&#34;: None,
                &#34;weightDaysOld&#34;: None,
            }
        nearest_weight = None
        nearest_diff = None
        errors = []
        min_time = datetime.min.time()
        experiment_date_time = datetime.combine(experiment_date, min_time)
        fasted_weights = [w for w in specimen_weights if w[&#34;weightFasted&#34;]]
        non_fasted_weights = [w for w in specimen_weights if not w[&#34;weightFasted&#34;]]
        if len(fasted_weights) &gt; 0:
            same_procedure_fasted_weights = [
                w for w in fasted_weights if procedure_group in w[&#34;weightParameterID&#34;]
            ]
            if len(same_procedure_fasted_weights) &gt; 0:
                specimen_weights = same_procedure_fasted_weights
            else:
                specimen_weights = non_fasted_weights
        for candidate_weight in specimen_weights:
            if (
                candidate_weight[&#34;weightValue&#34;] == &#34;null&#34;
                or candidate_weight[&#34;weightDate&#34;] == &#34;null&#34;
            ):
                continue
            candidate_weight_date = candidate_weight[&#34;weightDate&#34;]
            candidate_weight_time = datetime.combine(candidate_weight_date, min_time)
            # TODO: TypeError: unsupported operand type(s) for -: &#39;datetime.date&#39; and &#39;datetime.datetime&#39;
            candidate_diff = abs(
                unix_time_millis(experiment_date_time)
                - unix_time_millis(candidate_weight_time)
            )
            if nearest_weight is None:
                nearest_weight = candidate_weight
                nearest_diff = candidate_diff
                continue
            try:
                candidate_weight_value = float(candidate_weight[&#34;weightValue&#34;])
            except ValueError:
                errors.append(&#34;[PARSING] Failed to parse: &#34; + str(candidate_weight))
                continue

            try:
                nearest_weight_value = float(nearest_weight[&#34;weightValue&#34;])
            except ValueError:
                errors.append(
                    &#34;[PARSING] Failed to parse: &#34;
                    + str(nearest_weight[&#34;weightValue&#34;])
                    + &#34; &#34;
                    + procedure_group
                    + &#34; &#34;
                    + str(experiment_date)
                )
                continue

            if candidate_diff &lt; nearest_diff:
                nearest_weight = candidate_weight
                nearest_diff = candidate_diff
            elif candidate_diff == nearest_diff:
                if (
                    procedure_group is not None
                    and procedure_group in candidate_weight[&#34;weightParameterID&#34;]
                ):
                    if candidate_weight_value &gt; nearest_weight_value:
                        nearest_weight = candidate_weight
                        nearest_diff = candidate_diff
                elif &#34;_BWT&#34; in candidate_weight[&#34;weightParameterID&#34;]:
                    if candidate_weight_value &gt; nearest_weight_value:
                        nearest_weight = candidate_weight
                        nearest_diff = candidate_diff
                elif candidate_weight_value &gt; nearest_weight_value:
                    nearest_weight = candidate_weight
                    nearest_diff = candidate_diff

        days_diff = nearest_diff / 86400000 if nearest_diff is not None else 6

        if nearest_weight is not None and days_diff &lt; 5:
            return {**nearest_weight.asDict(), &#34;error&#34;: errors}
        else:
            return {
                &#34;sourceExperimentId&#34;: None,
                &#34;weightDate&#34;: None,
                &#34;weightValue&#34;: None,
                &#34;weightParameterID&#34;: None,
                &#34;weightDaysOld&#34;: None,
                &#34;error&#34;: errors,
            }

    def _add_special_dates(self, dcc_experiment_df: DataFrame):
        &#34;&#34;&#34;
        Takes in a DataFrame with experimental data, parses out the metadata values for special dates,
        and adds those values as new columns.
        &#34;&#34;&#34;
        for col_name, date_prefixes in {
            &#34;_dateOfBloodCollection&#34;: [
                &#34;date and time of blood collection = &#34;,
                &#34;date/time of blood collection = &#34;,
            ],
            &#34;_dateOfSacrifice&#34;: [
                &#34;date and time of sacrifice = &#34;,
                &#34;date of sacrifice = &#34;,
            ],
        }.items():
            escaped_prefixes = [prefix.replace(&#34;/&#34;, &#34;.&#34;) for prefix in date_prefixes]
            prefix_regex = f&#34;(?i)(.*)({&#39;|&#39;.join(escaped_prefixes)})(.*)&#34;
            dcc_experiment_df = dcc_experiment_df.withColumn(
                col_name + &#34;Array&#34;,
                expr(
                    f&#39;filter(metadata, metadataValue -&gt;  metadataValue rlike &#34;{prefix_regex}&#34; )&#39;
                ),
            )
            dcc_experiment_df = dcc_experiment_df.withColumn(
                col_name,
                regexp_extract(
                    col(col_name + &#34;Array&#34;).getItem(0), prefix_regex, 3
                ).astype(DateType()),
            )
        return dcc_experiment_df</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>luigi.contrib.spark.PySparkTask</li>
<li>luigi.contrib.spark.SparkSubmitTask</li>
<li>luigi.contrib.external_program.ExternalProgramTask</li>
<li>luigi.task.Task</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.name"><code class="name">var <span class="ident">name</span></code></dt>
<dd>
<div class="desc"><p>Name of the Spark task</p></div>
</dd>
<dt id="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.output_path"><code class="name">var <span class="ident">output_path</span></code></dt>
<dd>
<div class="desc"><p>Path of the output directory where the new parquet file will be generated.</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.app_options"><code class="name flex">
<span>def <span class="ident">app_options</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates the options pass to the PySpark job</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def app_options(self):
    &#34;&#34;&#34;
    Generates the options pass to the PySpark job
    &#34;&#34;&#34;
    return [
        self.input()[0].path,
        self.input()[1].path,
        self.input()[2].path,
        self.output().path,
    ]</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.generate_age_information"><code class="name flex">
<span>def <span class="ident">generate_age_information</span></span>(<span>self, dcc_experiment_df: pyspark.sql.dataframe.DataFrame, mice_df: pyspark.sql.dataframe.DataFrame)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_age_information(
    self, dcc_experiment_df: DataFrame, mice_df: DataFrame
):
    experiment_df_a = dcc_experiment_df.alias(&#34;exp&#34;)
    mice_df_a = mice_df.alias(&#34;mice&#34;)
    dcc_experiment_df = experiment_df_a.join(
        mice_df_a,
        (experiment_df_a[&#34;specimenID&#34;] == mice_df[&#34;_specimenID&#34;])
        &amp; (experiment_df_a[&#34;_centreID&#34;] == mice_df[&#34;_centreID&#34;]),
        &#34;left_outer&#34;,
    )
    dcc_experiment_df = self._add_special_dates(dcc_experiment_df)
    dcc_experiment_df = dcc_experiment_df.withColumn(
        &#34;ageInDays&#34;,
        datediff(
            when(
                col(&#34;_dateOfBloodCollection&#34;).isNotNull(),
                col(&#34;_dateOfBloodCollection&#34;),
            )
            .when(col(&#34;_dateOfSacrifice&#34;).isNotNull(), col(&#34;_dateOfSacrifice&#34;))
            .otherwise(col(&#34;_dateOfExperiment&#34;)),
            col(&#34;mice._DOB&#34;),
        ),
    )
    dcc_experiment_df = dcc_experiment_df.withColumn(
        &#34;ageInWeeks&#34;,
        udf(lambda x: math.floor(x / 7) if x is not None else None, IntegerType())(
            col(&#34;ageInDays&#34;)
        ),
    )
    return dcc_experiment_df.select(&#34;exp.*&#34;, &#34;ageInWeeks&#34;, &#34;ageInDays&#34;)</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.get_associated_body_weight"><code class="name flex">
<span>def <span class="ident">get_associated_body_weight</span></span>(<span>self, specimen_level_experiment_df: pyspark.sql.dataframe.DataFrame, mouse_specimen_df: pyspark.sql.dataframe.DataFrame, impress_df: pyspark.sql.dataframe.DataFrame) ‑> pyspark.sql.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Takes in DataFrame with Experimental data, one with Mouse Specimens and one with Impress information,
and applies the algorithm to select the associated BW to any given experiment
and calculate the age of experiment for the selected BW measurement.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_associated_body_weight(
    self,
    specimen_level_experiment_df: DataFrame,
    mouse_specimen_df: DataFrame,
    impress_df: DataFrame,
) -&gt; DataFrame:
    &#34;&#34;&#34;
    Takes in DataFrame with Experimental data, one with Mouse Specimens and one with Impress information,
    and applies the algorithm to select the associated BW to any given experiment
    and calculate the age of experiment for the selected BW measurement.
    &#34;&#34;&#34;
    # Explode the nested experiment DF structure so every row represents an observation
    weight_observations: DataFrame = specimen_level_experiment_df.withColumn(
        &#34;simpleParameter&#34;, explode_outer(&#34;simpleParameter&#34;)
    )

    # Select the parameter relevant pieces from the IMPReSS DF
    parameters = impress_df.select(
        &#34;pipelineKey&#34;,
        &#34;procedure.procedureKey&#34;,
        &#34;parameter.parameterKey&#34;,
        &#34;parameter.analysisWithBodyweight&#34;,
    ).distinct()

    # Filter the IMPReSS using the analysisWithBodyweight flag
    weight_parameters = parameters.where(
        col(&#34;analysisWithBodyweight&#34;).isin(
            [&#34;is_body_weight&#34;, &#34;is_fasted_body_weight&#34;]
        )
    )

    # Join both the  observations DF and the BW parameters DF to obtain the observations that are BW
    weight_observations = weight_observations.join(
        weight_parameters,
        (
            (weight_observations[&#34;_pipeline&#34;] == weight_parameters[&#34;pipelineKey&#34;])
            &amp; (
                weight_observations[&#34;_procedureID&#34;]
                == weight_parameters[&#34;procedureKey&#34;]
            )
            &amp; (
                weight_observations[&#34;simpleParameter._parameterID&#34;]
                == weight_parameters[&#34;parameterKey&#34;]
            )
        ),
    )
    # Create a boolean flag for fasted BW procedures
    weight_observations = weight_observations.withColumn(
        &#34;weightFasted&#34;, col(&#34;analysisWithBodyweight&#34;) == &#34;is_fasted_body_weight&#34;
    )

    weight_observations = weight_observations.select(
        &#34;specimenID&#34;,
        &#34;_centreID&#34;,
        col(&#34;unique_id&#34;).alias(&#34;sourceExperimentId&#34;),
        col(&#34;_dateOfExperiment&#34;).alias(&#34;weightDate&#34;),
        col(&#34;simpleParameter._parameterID&#34;).alias(&#34;weightParameterID&#34;),
        col(&#34;simpleParameter.value&#34;).alias(&#34;weightValue&#34;),
        &#34;weightFasted&#34;,
    )
    weight_observations = weight_observations.where(col(&#34;weightValue&#34;).isNotNull())

    # Join the body weight observations so we can determine the  age of the specimen for any BW measurement
    weight_observations = weight_observations.join(
        mouse_specimen_df,
        (weight_observations[&#34;specimenID&#34;] == mouse_specimen_df[&#34;_specimenID&#34;])
        &amp; (weight_observations[&#34;_centreID&#34;] == mouse_specimen_df[&#34;_centreID&#34;]),
    )
    weight_observations = weight_observations.withColumn(
        &#34;weightDaysOld&#34;, datediff(&#34;weightDate&#34;, &#34;_DOB&#34;)
    )

    #  Group the weight observations by Specimen
    weight_observations = weight_observations.groupBy(&#34;specimenID&#34;).agg(
        collect_set(
            struct(
                &#34;sourceExperimentId&#34;,
                &#34;weightDate&#34;,
                &#34;weightParameterID&#34;,
                &#34;weightValue&#34;,
                &#34;weightDaysOld&#34;,
                &#34;weightFasted&#34;,
            )
        ).alias(&#34;weight_observations&#34;)
    )

    # Create a temporary &#34;procedureGroup&#34; column to be used in the  BW selection
    specimen_level_experiment_df = specimen_level_experiment_df.withColumn(
        &#34;procedureGroup&#34;,
        udf(lambda prod_id: prod_id[: prod_id.rfind(&#34;_&#34;)], StringType())(
            col(&#34;_procedureID&#34;)
        ),
    )

    # Join all the observations with the BW observations grouped by specimen
    specimen_level_experiment_df = specimen_level_experiment_df.join(
        weight_observations, &#34;specimenID&#34;, &#34;left_outer&#34;
    )
    # Schema for the struct that is going to group all the associated BW data
    output_weight_schema = StructType(
        [
            StructField(&#34;sourceExperimentId&#34;, StringType()),
            StructField(&#34;weightDate&#34;, DateType()),
            StructField(&#34;weightParameterID&#34;, StringType()),
            StructField(&#34;weightValue&#34;, StringType()),
            StructField(&#34;weightDaysOld&#34;, IntegerType()),
            StructField(&#34;error&#34;, ArrayType(StringType())),
        ]
    )

    # Alias both the experiment and the specimen df so is easier to join and manipulate
    experiment_df_a = specimen_level_experiment_df.alias(&#34;exp&#34;)
    mice_df_a = mouse_specimen_df.alias(&#34;mice&#34;)

    specimen_level_experiment_df = experiment_df_a.join(
        mice_df_a,
        (
            specimen_level_experiment_df[&#34;specimenID&#34;]
            == mouse_specimen_df[&#34;_specimenID&#34;]
        )
        &amp; (
            specimen_level_experiment_df[&#34;_centreID&#34;]
            == mouse_specimen_df[&#34;_centreID&#34;]
        ),
        &#34;left_outer&#34;,
    )

    # Add special dates to the experiment x specimen dataframe
    # for some experiments the date of sacrifice or date of blood collection
    # has to be used as reference for age and  BW calculations
    specimen_level_experiment_df = self._add_special_dates(
        specimen_level_experiment_df
    )
    get_associated_body_weight_udf = udf(
        self._get_closest_weight, output_weight_schema
    )
    specimen_level_experiment_df = specimen_level_experiment_df.withColumn(
        &#34;weight&#34;,
        get_associated_body_weight_udf(
            when(
                col(&#34;_dateOfBloodCollection&#34;).isNotNull(),
                col(&#34;_dateOfBloodCollection&#34;),
            )
            .when(col(&#34;_dateOfSacrifice&#34;).isNotNull(), col(&#34;_dateOfSacrifice&#34;))
            .otherwise(col(&#34;_dateOfExperiment&#34;)),
            col(&#34;procedureGroup&#34;),
            col(&#34;weight_observations&#34;),
        ),
    )
    specimen_level_experiment_df = specimen_level_experiment_df.select(
        &#34;exp.*&#34;, &#34;weight&#34;
    )
    return specimen_level_experiment_df</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>self, sc, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads the given the Experiment parquet, the Specimen parquet and the Impress parquet,
and uses them to calculate the age of the specimen at any given experiment date and to associate
BW data to every experiment when possible.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main(self, sc, *args):
    &#34;&#34;&#34;
    Loads the given the Experiment parquet, the Specimen parquet and the Impress parquet,
    and uses them to calculate the age of the specimen at any given experiment date and to associate
    BW data to every experiment when possible.
    &#34;&#34;&#34;
    spark = SparkSession(sc)
    spark.sql(&#34;set spark.sql.legacy.timeParserPolicy=LEGACY&#34;)
    spark.sql(&#34;set spark.sql.legacy.parquet.datetimeRebaseModeInWrite=LEGACY&#34;)
    experiment_parquet_path = args[0]
    mouse_parquet_path = args[1]
    pipeline_parquet_path = args[2]
    output_path = args[3]
    experiment_df = spark.read.parquet(experiment_parquet_path)
    mouse_df = spark.read.parquet(mouse_parquet_path)
    pipeline_df = spark.read.parquet(pipeline_parquet_path)
    experiment_df = self.get_associated_body_weight(
        experiment_df, mouse_df, pipeline_df
    )
    experiment_df = self.generate_age_information(experiment_df, mouse_df)
    experiment_df.write.parquet(output_path)</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.output"><code class="name flex">
<span>def <span class="ident">output</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the full parquet path as an output for the Luigi Task
(e.g. impc/dr15.2/parquet/experiment_with_bw_age_parquet)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def output(self):
    &#34;&#34;&#34;
    Returns the full parquet path as an output for the Luigi Task
    (e.g. impc/dr15.2/parquet/experiment_with_bw_age_parquet)
    &#34;&#34;&#34;
    return ImpcConfig().get_target(
        f&#34;{self.output_path}experiment_with_bw_age_parquet&#34;
    )</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.requires"><code class="name flex">
<span>def <span class="ident">requires</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the luigi
task dependencies</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def requires(self):
    &#34;&#34;&#34;
    Defines the luigi  task dependencies
    &#34;&#34;&#34;
    return [ExperimentParameterDerivator(), MouseNormalizer(), ImpressExtractor()]</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<div style="max-width: 300px; text-align: center">
<img src="https://www.mousephenotype.org/wp-content/themes/impc/images/IMPC_10_YEAR_Logo.svg" alt="IMPC Logo">
</div>
<h1 style="text-align: center; max-width: 300px;">IMPC ETL</h1>
<h2 style="text-align: center; max-width: 300px;">Reference Documentation</h2>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="impc_etl.jobs.transform" href="index.html">impc_etl.jobs.transform</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor" href="#impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor">ExperimentBWAgeProcessor</a></code></h4>
<ul class="">
<li><code><a title="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.app_options" href="#impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.app_options">app_options</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.generate_age_information" href="#impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.generate_age_information">generate_age_information</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.get_associated_body_weight" href="#impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.get_associated_body_weight">get_associated_body_weight</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.main" href="#impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.main">main</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.name" href="#impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.name">name</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.output" href="#impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.output">output</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.output_path" href="#impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.output_path">output_path</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.requires" href="#impc_etl.jobs.transform.experiment_bw_age.ExperimentBWAgeProcessor.requires">requires</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p><span></span></p>
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>