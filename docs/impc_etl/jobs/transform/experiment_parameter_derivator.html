<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>impc_etl.jobs.transform.experiment_parameter_derivator API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>impc_etl.jobs.transform.experiment_parameter_derivator</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from typing import List, Dict

import luigi
from luigi.contrib.spark import PySparkTask
from pyspark.sql import SparkSession, DataFrame
from pyspark.sql.functions import (
    col,
    lit,
    when,
    concat,
    explode,
    concat_ws,
    collect_list,
    collect_set,
    struct,
    udf,
    sum,
    size,
    expr,
)
from pyspark.sql.types import (
    ArrayType,
    StringType,
    LongType,
)

from impc_etl.config.constants import Constants
from impc_etl.jobs.extract import ImpressExtractor
from impc_etl.shared.utils import (
    extract_parameters_from_derivation,
    has_column,
)
from impc_etl.workflow.config import ImpcConfig
from impc_etl.workflow.normalization import (
    ExperimentNormalizer,
    LineExperimentNormalizer,
)


class ParameterDerivator(PySparkTask):
    experiment_level = luigi.Parameter()
    dcc_xml_path = luigi.Parameter()
    imits_colonies_tsv_path = luigi.Parameter()
    output_path = luigi.Parameter()

    def output(self):
        return ImpcConfig().get_target(
            f&#34;{self.output_path}{self.experiment_level}_derived_parquet&#34;
        )

    def app_options(self):
        return [self.input()[0].path, self.input()[1].path, self.output().path]

    def main(self, sc, *args):
        spark = SparkSession(sc)
        experiment_parquet_path = args[0]
        pipeline_parquet_path = args[1]
        output_path = args[2]
        dcc_experiment_df = spark.read.parquet(experiment_parquet_path)
        impress_df = spark.read.parquet(pipeline_parquet_path)
        europhenome_derivations_json = spark.sparkContext.parallelize(
            Constants.EUROPHENOME_DERIVATIONS
        )
        europhenome_derivations_df = spark.read.json(europhenome_derivations_json)
        europhenome_derivations_df = europhenome_derivations_df.alias(&#34;europhenome&#34;)

        europhenome_parameters = [
            derivation[&#34;europhenomeParameter&#34;]
            for derivation in Constants.EUROPHENOME_DERIVATIONS
        ]

        # Filter impress DataFrame to get only the derived parameters, filtering out archive and unimplemented
        derived_parameters: DataFrame = (
            impress_df.where(
                (
                    (impress_df[&#34;parameter.isDerived&#34;] == True)
                    &amp; (impress_df[&#34;parameter.isDeprecated&#34;] == False)
                    &amp; (~impress_df[&#34;parameter.derivation&#34;].contains(&#34;archived&#34;))
                    &amp; (~impress_df[&#34;parameter.derivation&#34;].contains(&#34;unimplemented&#34;))
                )
                | (impress_df[&#34;parameter.parameterKey&#34;].isin(europhenome_parameters))
            )
            .where(
                ~impress_df[&#34;parameter.parameterKey&#34;].isin(
                    Constants.DERIVED_PARAMETER_BANLIST
                )
            )
            .select(
                &#34;pipelineKey&#34;,
                &#34;procedure.procedureKey&#34;,
                &#34;parameter.parameterKey&#34;,
                &#34;parameter.derivation&#34;,
                &#34;parameter.type&#34;,
                &#34;unitName&#34;,
            )
            .dropDuplicates()
        )

        derived_parameters = derived_parameters.join(
            europhenome_derivations_df,
            col(&#34;parameterKey&#34;) == europhenome_derivations_df[&#34;europhenomeParameter&#34;],
            &#34;left_outer&#34;,
        )
        derived_parameters = derived_parameters.withColumn(
            &#34;derivation&#34;,
            when(
                col(&#34;europhenomeDerivation&#34;).isNotNull(), col(&#34;europhenomeDerivation&#34;)
            ).otherwise(col(&#34;derivation&#34;)),
        )
        derived_parameters = derived_parameters.drop(&#34;europhenome.*&#34;)

        # Use a Python UDF to extract the keys of the parameters involved in the derivations as a list
        extract_parameters_from_derivation_udf = udf(
            extract_parameters_from_derivation, ArrayType(StringType())
        )

        derived_parameters = derived_parameters.withColumn(
            &#34;derivationInputs&#34;, extract_parameters_from_derivation_udf(&#34;derivation&#34;)
        )

        # Explode the derivation inputs
        derived_parameters_ex = derived_parameters.withColumn(
            &#34;derivationInput&#34;, explode(&#34;derivationInputs&#34;)
        ).select(
            &#34;pipelineKey&#34;,
            &#34;procedureKey&#34;,
            &#34;parameterKey&#34;,
            &#34;derivation&#34;,
            &#34;derivationInput&#34;,
        )

        # Compute the derivation inputs for simple, procedure and series parameters
        # Each input is has the form &lt;PARAMETER_KEY&gt;$&lt;PARAMETER_VALUE&gt;
        # If the parameter has increments the inputs will have the form
        # &lt;PARAMETER_KEY&gt;$INCREMENT_1$&lt;PARAMETER_VALUE&gt;|INCREMENT_1$&lt;PARAMETER_VALUE&gt;
        experiments_simple = _get_inputs_by_parameter_type(
            dcc_experiment_df, derived_parameters_ex, &#34;simpleParameter&#34;
        )
        experiments_metadata = _get_inputs_by_parameter_type(
            dcc_experiment_df, derived_parameters_ex, &#34;procedureMetadata&#34;
        )
        experiments_vs_derivations = experiments_simple.union(experiments_metadata)

        if has_column(dcc_experiment_df, &#34;seriesParameter&#34;):
            experiments_series = _get_inputs_by_parameter_type(
                dcc_experiment_df, derived_parameters_ex, &#34;seriesParameter&#34;
            )
            experiments_vs_derivations = experiments_vs_derivations.union(
                experiments_series
            )
        # Collect the derivation inputs in a comma separated list
        experiments_vs_derivations = experiments_vs_derivations.groupby(
            &#34;unique_id&#34;, &#34;pipelineKey&#34;, &#34;procedureKey&#34;, &#34;parameterKey&#34;, &#34;derivation&#34;
        ).agg(
            concat_ws(
                &#34;,&#34;, collect_list(experiments_vs_derivations[&#34;derivationInput&#34;])
            ).alias(&#34;derivationInputStr&#34;)
        )

        experiments_vs_derivations = experiments_vs_derivations.join(
            derived_parameters.drop(&#34;derivation&#34;),
            [&#34;pipelineKey&#34;, &#34;procedureKey&#34;, &#34;parameterKey&#34;],
        )

        # Check if the experiment contains all the parameter values to perform the derivation
        experiments_vs_derivations = experiments_vs_derivations.withColumn(
            &#34;derivationInput&#34;, explode(&#34;derivationInputs&#34;)
        )
        experiments_vs_derivations = experiments_vs_derivations.withColumn(
            &#34;isPresent&#34;,
            when(
                col(&#34;derivationInputStr&#34;).contains(col(&#34;derivationInput&#34;)), 1
            ).otherwise(0),
        )
        experiments_vs_derivations = experiments_vs_derivations.groupBy(
            [
                &#34;unique_id&#34;,
                &#34;pipelineKey&#34;,
                &#34;procedureKey&#34;,
                &#34;parameterKey&#34;,
                &#34;derivationInputStr&#34;,
                &#34;derivationInputs&#34;,
                &#34;derivation&#34;,
            ]
        ).agg(sum(&#34;isPresent&#34;).alias(&#34;presentColumns&#34;))

        experiments_vs_derivations = experiments_vs_derivations.withColumn(
            &#34;isComplete&#34;,
            when((size(col(&#34;derivationInputs&#34;)) == col(&#34;presentColumns&#34;)), lit(True))
            .when(
                (
                    (col(&#34;derivation&#34;).contains(&#34;retinaCombined&#34;))
                    | (col(&#34;derivation&#34;).contains(&#34;ifElse&#34;))
                )
                &amp; (size(col(&#34;derivationInputs&#34;)) &gt; 0),
                lit(True),
            )
            .otherwise(lit(False)),
        )
        experiments_vs_derivations = experiments_vs_derivations.withColumn(
            &#34;derivationInputStr&#34;, concat(&#34;derivation&#34;, lit(&#34;;&#34;), &#34;derivationInputStr&#34;)
        )
        spark.udf.registerJavaFunction(
            &#34;phenodcc_derivator&#34;,
            &#34;org.mousephenotype.dcc.derived.parameters.SparkDerivator&#34;,
            StringType(),
        )

        results_df = experiments_vs_derivations.select(
            &#34;unique_id&#34;,
            &#34;pipelineKey&#34;,
            &#34;procedureKey&#34;,
            &#34;parameterKey&#34;,
            &#34;presentColumns&#34;,
            &#34;isComplete&#34;,
            &#34;derivationInputStr&#34;,
        ).dropDuplicates()
        results_df = results_df.withColumn(
            &#34;result&#34;,
            when(
                (col(&#34;isComplete&#34;) == True),
                expr(&#34;phenodcc_derivator(derivationInputStr)&#34;),
            ).otherwise(lit(None)),
        )

        # Filtering not valid numeric values
        results_df = results_df.withColumn(
            &#34;result&#34;,
            when(
                (col(&#34;result&#34;) == &#34;NaN&#34;)
                | (col(&#34;result&#34;) == &#34;Infinity&#34;)
                | (col(&#34;result&#34;) == &#34;-Infinity&#34;),
                lit(None),
            ).otherwise(col(&#34;result&#34;)),
        )
        results_df = results_df.where(col(&#34;result&#34;).isNotNull())
        results_df = results_df.join(
            derived_parameters, [&#34;pipelineKey&#34;, &#34;procedureKey&#34;, &#34;parameterKey&#34;]
        )

        result_schema_fields = [
            results_df[&#34;parameterKey&#34;].alias(&#34;_parameterID&#34;),
            results_df[&#34;unitName&#34;].alias(&#34;_unit&#34;),
            lit(None).cast(StringType()).alias(&#34;parameterStatus&#34;),
            results_df[&#34;result&#34;].alias(&#34;value&#34;),
        ]
        if self.experiment_level == &#34;experiment&#34;:
            result_schema_fields.insert(
                1, lit(None).cast(LongType()).alias(&#34;_sequenceID&#34;)
            )
        elif has_column(dcc_experiment_df, &#34;simpleParameter._VALUE&#34;):
            result_schema_fields.insert(0, lit(None).cast(StringType()).alias(&#34;_VALUE&#34;))
        result_struct = struct(*result_schema_fields)
        results_df = results_df.groupBy(&#34;unique_id&#34;, &#34;pipelineKey&#34;, &#34;procedureKey&#34;).agg(
            collect_list(result_struct).alias(&#34;results&#34;)
        )
        results_df = results_df.withColumnRenamed(&#34;unique_id&#34;, &#34;unique_id_result&#34;)

        dcc_experiment_df = dcc_experiment_df.join(
            results_df,
            (dcc_experiment_df[&#34;unique_id&#34;] == results_df[&#34;unique_id_result&#34;])
            &amp; (dcc_experiment_df[&#34;_procedureID&#34;] == results_df[&#34;procedureKey&#34;])
            &amp; (dcc_experiment_df[&#34;_pipeline&#34;] == results_df[&#34;pipelineKey&#34;]),
            &#34;left_outer&#34;,
        )

        simple_parameter_type = None

        for c_type in dcc_experiment_df.dtypes:
            if c_type[0] == &#34;simpleParameter&#34;:
                simple_parameter_type = c_type[1]
                break
        merge_simple_parameters = udf(_merge_simple_parameters, simple_parameter_type)
        dcc_experiment_df = dcc_experiment_df.withColumn(
            &#34;simpleParameter&#34;,
            when(
                (col(&#34;results&#34;).isNotNull() &amp; col(&#34;simpleParameter&#34;).isNotNull()),
                merge_simple_parameters(col(&#34;simpleParameter&#34;), col(&#34;results&#34;)),
            )
            .when(col(&#34;simpleParameter&#34;).isNull(), col(&#34;results&#34;))
            .otherwise(col(&#34;simpleParameter&#34;)),
        )
        dcc_experiment_df = dcc_experiment_df.drop(
            &#34;complete_derivations.unique_id&#34;,
            &#34;unique_id_result&#34;,
            &#34;pipelineKey&#34;,
            &#34;procedureKey&#34;,
            &#34;parameterKey&#34;,
            &#34;results&#34;,
        )
        dcc_experiment_df.write.parquet(output_path)


def _merge_simple_parameters(simple_parameters: List[Dict], results: [Dict]):
    merged_array = []
    if results is None or simple_parameters is None:
        return simple_parameters
    result_parameter_keys = {result[&#34;_parameterID&#34;]: result for result in results}
    for simple_parameter in simple_parameters:
        parameter_id = simple_parameter[&#34;_parameterID&#34;]
        if parameter_id in result_parameter_keys:
            merged_array.append(result_parameter_keys[parameter_id])
        else:
            merged_array.append(simple_parameter)
    simple_parameter_keys = {
        simple_parameter[&#34;_parameterID&#34;]: simple_parameter
        for simple_parameter in simple_parameters
    }
    for result in results:
        parameter_id = result[&#34;_parameterID&#34;]
        if parameter_id not in simple_parameter_keys:
            merged_array.append(result)
    return merged_array


def _get_inputs_by_parameter_type(
    dcc_experiment_df, derived_parameters_ex, parameter_type
):
    experiments_by_type = dcc_experiment_df.select(
        &#34;unique_id&#34;,
        &#34;_pipeline&#34;,
        &#34;_procedureID&#34;,
        explode(parameter_type).alias(parameter_type),
    )
    if parameter_type == &#34;seriesParameter&#34;:
        experiments_by_type = experiments_by_type.select(
            &#34;unique_id&#34;,
            &#34;_pipeline&#34;,
            &#34;_procedureID&#34;,
            col(parameter_type + &#34;._parameterID&#34;).alias(&#34;_parameterID&#34;),
            explode(parameter_type + &#34;.value&#34;).alias(&#34;value&#34;),
        )
        experiments_by_type = experiments_by_type.withColumn(
            &#34;value&#34;, concat(col(&#34;value._incrementValue&#34;), lit(&#34;|&#34;), col(&#34;value._VALUE&#34;))
        )
        experiments_by_type = experiments_by_type.groupBy(
            &#34;unique_id&#34;, &#34;_pipeline&#34;, &#34;_parameterID&#34;, &#34;_procedureID&#34;
        ).agg(concat_ws(&#34;$&#34;, collect_set(&#34;value&#34;)).alias(&#34;value&#34;))

    parameter_id_column = (
        parameter_type + &#34;._parameterID&#34;
        if parameter_type != &#34;seriesParameter&#34;
        else &#34;_parameterID&#34;
    )
    parameter_value_column = (
        parameter_type + &#34;.value&#34; if parameter_type != &#34;seriesParameter&#34; else &#34;value&#34;
    )
    experiments_vs_derivations = derived_parameters_ex.join(
        experiments_by_type,
        (
            (
                experiments_by_type[parameter_id_column]
                == derived_parameters_ex[&#34;derivationInput&#34;]
            )
            &amp; (
                experiments_by_type[&#34;_procedureID&#34;]
                == derived_parameters_ex.procedureKey
            )
            &amp; (experiments_by_type[&#34;_pipeline&#34;] == derived_parameters_ex.pipelineKey)
        ),
    )
    experiments_vs_derivations: DataFrame = experiments_vs_derivations.withColumn(
        &#34;derivationInput&#34;,
        concat(col(&#34;derivationInput&#34;), lit(&#34;$&#34;), col(parameter_value_column)),
    )
    return (
        experiments_vs_derivations.drop(parameter_type, &#34;_procedureID&#34;, &#34;_pipeline&#34;)
        if parameter_type != &#34;seriesParameter&#34;
        else experiments_vs_derivations.drop(
            &#34;value&#34;, &#34;_parameterID&#34;, &#34;_procedureID&#34;, &#34;_pipeline&#34;
        )
    )


class ExperimentParameterDerivator(ParameterDerivator):
    name = &#34;IMPC_Experiment_Parameter_Derivator&#34;
    experiment_level = &#34;experiment&#34;

    def requires(self):
        return [ExperimentNormalizer(entity_type=&#34;experiment&#34;), ImpressExtractor()]


class LineParameterDerivator(ParameterDerivator):
    name = &#34;IMPC_Line_Parameter_Derivator&#34;
    experiment_level = &#34;line&#34;

    def requires(self):
        return [LineExperimentNormalizer(entity_type=&#34;line&#34;), ImpressExtractor()]</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator"><code class="flex name class">
<span>class <span class="ident">ExperimentParameterDerivator</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Template task for running an inline PySpark job</p>
<p>Simply implement the <code>main</code> method in your subclass</p>
<p>You can optionally define package names to be distributed to the cluster
with <code>py_packages</code> (uses luigi's global py-packages configuration by default)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ExperimentParameterDerivator(ParameterDerivator):
    name = &#34;IMPC_Experiment_Parameter_Derivator&#34;
    experiment_level = &#34;experiment&#34;

    def requires(self):
        return [ExperimentNormalizer(entity_type=&#34;experiment&#34;), ImpressExtractor()]</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator">ParameterDerivator</a></li>
<li>luigi.contrib.spark.PySparkTask</li>
<li>luigi.contrib.spark.SparkSubmitTask</li>
<li>luigi.contrib.external_program.ExternalProgramTask</li>
<li>luigi.task.Task</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator.experiment_level"><code class="name">var <span class="ident">experiment_level</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator.name"><code class="name">var <span class="ident">name</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator.requires"><code class="name flex">
<span>def <span class="ident">requires</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>The Tasks that this Task depends on.</p>
<p>A Task will only run if all of the Tasks that it requires are completed.
If your Task does not require any other Tasks, then you don't need to
override this method. Otherwise, a subclass can override this method
to return a single Task, a list of Task instances, or a dict whose
values are Task instances.</p>
<p>See :ref:<code>Task.requires</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def requires(self):
    return [ExperimentNormalizer(entity_type=&#34;experiment&#34;), ImpressExtractor()]</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator">ParameterDerivator</a></b></code>:
<ul class="hlist">
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.app_options" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.app_options">app_options</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.main" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.main">main</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.output" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.output">output</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="impc_etl.jobs.transform.experiment_parameter_derivator.LineParameterDerivator"><code class="flex name class">
<span>class <span class="ident">LineParameterDerivator</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Template task for running an inline PySpark job</p>
<p>Simply implement the <code>main</code> method in your subclass</p>
<p>You can optionally define package names to be distributed to the cluster
with <code>py_packages</code> (uses luigi's global py-packages configuration by default)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LineParameterDerivator(ParameterDerivator):
    name = &#34;IMPC_Line_Parameter_Derivator&#34;
    experiment_level = &#34;line&#34;

    def requires(self):
        return [LineExperimentNormalizer(entity_type=&#34;line&#34;), ImpressExtractor()]</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator">ParameterDerivator</a></li>
<li>luigi.contrib.spark.PySparkTask</li>
<li>luigi.contrib.spark.SparkSubmitTask</li>
<li>luigi.contrib.external_program.ExternalProgramTask</li>
<li>luigi.task.Task</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="impc_etl.jobs.transform.experiment_parameter_derivator.LineParameterDerivator.experiment_level"><code class="name">var <span class="ident">experiment_level</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="impc_etl.jobs.transform.experiment_parameter_derivator.LineParameterDerivator.name"><code class="name">var <span class="ident">name</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="impc_etl.jobs.transform.experiment_parameter_derivator.LineParameterDerivator.requires"><code class="name flex">
<span>def <span class="ident">requires</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>The Tasks that this Task depends on.</p>
<p>A Task will only run if all of the Tasks that it requires are completed.
If your Task does not require any other Tasks, then you don't need to
override this method. Otherwise, a subclass can override this method
to return a single Task, a list of Task instances, or a dict whose
values are Task instances.</p>
<p>See :ref:<code>Task.requires</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def requires(self):
    return [LineExperimentNormalizer(entity_type=&#34;line&#34;), ImpressExtractor()]</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator">ParameterDerivator</a></b></code>:
<ul class="hlist">
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.app_options" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.app_options">app_options</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.main" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.main">main</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.output" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.output">output</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator"><code class="flex name class">
<span>class <span class="ident">ParameterDerivator</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Template task for running an inline PySpark job</p>
<p>Simply implement the <code>main</code> method in your subclass</p>
<p>You can optionally define package names to be distributed to the cluster
with <code>py_packages</code> (uses luigi's global py-packages configuration by default)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ParameterDerivator(PySparkTask):
    experiment_level = luigi.Parameter()
    dcc_xml_path = luigi.Parameter()
    imits_colonies_tsv_path = luigi.Parameter()
    output_path = luigi.Parameter()

    def output(self):
        return ImpcConfig().get_target(
            f&#34;{self.output_path}{self.experiment_level}_derived_parquet&#34;
        )

    def app_options(self):
        return [self.input()[0].path, self.input()[1].path, self.output().path]

    def main(self, sc, *args):
        spark = SparkSession(sc)
        experiment_parquet_path = args[0]
        pipeline_parquet_path = args[1]
        output_path = args[2]
        dcc_experiment_df = spark.read.parquet(experiment_parquet_path)
        impress_df = spark.read.parquet(pipeline_parquet_path)
        europhenome_derivations_json = spark.sparkContext.parallelize(
            Constants.EUROPHENOME_DERIVATIONS
        )
        europhenome_derivations_df = spark.read.json(europhenome_derivations_json)
        europhenome_derivations_df = europhenome_derivations_df.alias(&#34;europhenome&#34;)

        europhenome_parameters = [
            derivation[&#34;europhenomeParameter&#34;]
            for derivation in Constants.EUROPHENOME_DERIVATIONS
        ]

        # Filter impress DataFrame to get only the derived parameters, filtering out archive and unimplemented
        derived_parameters: DataFrame = (
            impress_df.where(
                (
                    (impress_df[&#34;parameter.isDerived&#34;] == True)
                    &amp; (impress_df[&#34;parameter.isDeprecated&#34;] == False)
                    &amp; (~impress_df[&#34;parameter.derivation&#34;].contains(&#34;archived&#34;))
                    &amp; (~impress_df[&#34;parameter.derivation&#34;].contains(&#34;unimplemented&#34;))
                )
                | (impress_df[&#34;parameter.parameterKey&#34;].isin(europhenome_parameters))
            )
            .where(
                ~impress_df[&#34;parameter.parameterKey&#34;].isin(
                    Constants.DERIVED_PARAMETER_BANLIST
                )
            )
            .select(
                &#34;pipelineKey&#34;,
                &#34;procedure.procedureKey&#34;,
                &#34;parameter.parameterKey&#34;,
                &#34;parameter.derivation&#34;,
                &#34;parameter.type&#34;,
                &#34;unitName&#34;,
            )
            .dropDuplicates()
        )

        derived_parameters = derived_parameters.join(
            europhenome_derivations_df,
            col(&#34;parameterKey&#34;) == europhenome_derivations_df[&#34;europhenomeParameter&#34;],
            &#34;left_outer&#34;,
        )
        derived_parameters = derived_parameters.withColumn(
            &#34;derivation&#34;,
            when(
                col(&#34;europhenomeDerivation&#34;).isNotNull(), col(&#34;europhenomeDerivation&#34;)
            ).otherwise(col(&#34;derivation&#34;)),
        )
        derived_parameters = derived_parameters.drop(&#34;europhenome.*&#34;)

        # Use a Python UDF to extract the keys of the parameters involved in the derivations as a list
        extract_parameters_from_derivation_udf = udf(
            extract_parameters_from_derivation, ArrayType(StringType())
        )

        derived_parameters = derived_parameters.withColumn(
            &#34;derivationInputs&#34;, extract_parameters_from_derivation_udf(&#34;derivation&#34;)
        )

        # Explode the derivation inputs
        derived_parameters_ex = derived_parameters.withColumn(
            &#34;derivationInput&#34;, explode(&#34;derivationInputs&#34;)
        ).select(
            &#34;pipelineKey&#34;,
            &#34;procedureKey&#34;,
            &#34;parameterKey&#34;,
            &#34;derivation&#34;,
            &#34;derivationInput&#34;,
        )

        # Compute the derivation inputs for simple, procedure and series parameters
        # Each input is has the form &lt;PARAMETER_KEY&gt;$&lt;PARAMETER_VALUE&gt;
        # If the parameter has increments the inputs will have the form
        # &lt;PARAMETER_KEY&gt;$INCREMENT_1$&lt;PARAMETER_VALUE&gt;|INCREMENT_1$&lt;PARAMETER_VALUE&gt;
        experiments_simple = _get_inputs_by_parameter_type(
            dcc_experiment_df, derived_parameters_ex, &#34;simpleParameter&#34;
        )
        experiments_metadata = _get_inputs_by_parameter_type(
            dcc_experiment_df, derived_parameters_ex, &#34;procedureMetadata&#34;
        )
        experiments_vs_derivations = experiments_simple.union(experiments_metadata)

        if has_column(dcc_experiment_df, &#34;seriesParameter&#34;):
            experiments_series = _get_inputs_by_parameter_type(
                dcc_experiment_df, derived_parameters_ex, &#34;seriesParameter&#34;
            )
            experiments_vs_derivations = experiments_vs_derivations.union(
                experiments_series
            )
        # Collect the derivation inputs in a comma separated list
        experiments_vs_derivations = experiments_vs_derivations.groupby(
            &#34;unique_id&#34;, &#34;pipelineKey&#34;, &#34;procedureKey&#34;, &#34;parameterKey&#34;, &#34;derivation&#34;
        ).agg(
            concat_ws(
                &#34;,&#34;, collect_list(experiments_vs_derivations[&#34;derivationInput&#34;])
            ).alias(&#34;derivationInputStr&#34;)
        )

        experiments_vs_derivations = experiments_vs_derivations.join(
            derived_parameters.drop(&#34;derivation&#34;),
            [&#34;pipelineKey&#34;, &#34;procedureKey&#34;, &#34;parameterKey&#34;],
        )

        # Check if the experiment contains all the parameter values to perform the derivation
        experiments_vs_derivations = experiments_vs_derivations.withColumn(
            &#34;derivationInput&#34;, explode(&#34;derivationInputs&#34;)
        )
        experiments_vs_derivations = experiments_vs_derivations.withColumn(
            &#34;isPresent&#34;,
            when(
                col(&#34;derivationInputStr&#34;).contains(col(&#34;derivationInput&#34;)), 1
            ).otherwise(0),
        )
        experiments_vs_derivations = experiments_vs_derivations.groupBy(
            [
                &#34;unique_id&#34;,
                &#34;pipelineKey&#34;,
                &#34;procedureKey&#34;,
                &#34;parameterKey&#34;,
                &#34;derivationInputStr&#34;,
                &#34;derivationInputs&#34;,
                &#34;derivation&#34;,
            ]
        ).agg(sum(&#34;isPresent&#34;).alias(&#34;presentColumns&#34;))

        experiments_vs_derivations = experiments_vs_derivations.withColumn(
            &#34;isComplete&#34;,
            when((size(col(&#34;derivationInputs&#34;)) == col(&#34;presentColumns&#34;)), lit(True))
            .when(
                (
                    (col(&#34;derivation&#34;).contains(&#34;retinaCombined&#34;))
                    | (col(&#34;derivation&#34;).contains(&#34;ifElse&#34;))
                )
                &amp; (size(col(&#34;derivationInputs&#34;)) &gt; 0),
                lit(True),
            )
            .otherwise(lit(False)),
        )
        experiments_vs_derivations = experiments_vs_derivations.withColumn(
            &#34;derivationInputStr&#34;, concat(&#34;derivation&#34;, lit(&#34;;&#34;), &#34;derivationInputStr&#34;)
        )
        spark.udf.registerJavaFunction(
            &#34;phenodcc_derivator&#34;,
            &#34;org.mousephenotype.dcc.derived.parameters.SparkDerivator&#34;,
            StringType(),
        )

        results_df = experiments_vs_derivations.select(
            &#34;unique_id&#34;,
            &#34;pipelineKey&#34;,
            &#34;procedureKey&#34;,
            &#34;parameterKey&#34;,
            &#34;presentColumns&#34;,
            &#34;isComplete&#34;,
            &#34;derivationInputStr&#34;,
        ).dropDuplicates()
        results_df = results_df.withColumn(
            &#34;result&#34;,
            when(
                (col(&#34;isComplete&#34;) == True),
                expr(&#34;phenodcc_derivator(derivationInputStr)&#34;),
            ).otherwise(lit(None)),
        )

        # Filtering not valid numeric values
        results_df = results_df.withColumn(
            &#34;result&#34;,
            when(
                (col(&#34;result&#34;) == &#34;NaN&#34;)
                | (col(&#34;result&#34;) == &#34;Infinity&#34;)
                | (col(&#34;result&#34;) == &#34;-Infinity&#34;),
                lit(None),
            ).otherwise(col(&#34;result&#34;)),
        )
        results_df = results_df.where(col(&#34;result&#34;).isNotNull())
        results_df = results_df.join(
            derived_parameters, [&#34;pipelineKey&#34;, &#34;procedureKey&#34;, &#34;parameterKey&#34;]
        )

        result_schema_fields = [
            results_df[&#34;parameterKey&#34;].alias(&#34;_parameterID&#34;),
            results_df[&#34;unitName&#34;].alias(&#34;_unit&#34;),
            lit(None).cast(StringType()).alias(&#34;parameterStatus&#34;),
            results_df[&#34;result&#34;].alias(&#34;value&#34;),
        ]
        if self.experiment_level == &#34;experiment&#34;:
            result_schema_fields.insert(
                1, lit(None).cast(LongType()).alias(&#34;_sequenceID&#34;)
            )
        elif has_column(dcc_experiment_df, &#34;simpleParameter._VALUE&#34;):
            result_schema_fields.insert(0, lit(None).cast(StringType()).alias(&#34;_VALUE&#34;))
        result_struct = struct(*result_schema_fields)
        results_df = results_df.groupBy(&#34;unique_id&#34;, &#34;pipelineKey&#34;, &#34;procedureKey&#34;).agg(
            collect_list(result_struct).alias(&#34;results&#34;)
        )
        results_df = results_df.withColumnRenamed(&#34;unique_id&#34;, &#34;unique_id_result&#34;)

        dcc_experiment_df = dcc_experiment_df.join(
            results_df,
            (dcc_experiment_df[&#34;unique_id&#34;] == results_df[&#34;unique_id_result&#34;])
            &amp; (dcc_experiment_df[&#34;_procedureID&#34;] == results_df[&#34;procedureKey&#34;])
            &amp; (dcc_experiment_df[&#34;_pipeline&#34;] == results_df[&#34;pipelineKey&#34;]),
            &#34;left_outer&#34;,
        )

        simple_parameter_type = None

        for c_type in dcc_experiment_df.dtypes:
            if c_type[0] == &#34;simpleParameter&#34;:
                simple_parameter_type = c_type[1]
                break
        merge_simple_parameters = udf(_merge_simple_parameters, simple_parameter_type)
        dcc_experiment_df = dcc_experiment_df.withColumn(
            &#34;simpleParameter&#34;,
            when(
                (col(&#34;results&#34;).isNotNull() &amp; col(&#34;simpleParameter&#34;).isNotNull()),
                merge_simple_parameters(col(&#34;simpleParameter&#34;), col(&#34;results&#34;)),
            )
            .when(col(&#34;simpleParameter&#34;).isNull(), col(&#34;results&#34;))
            .otherwise(col(&#34;simpleParameter&#34;)),
        )
        dcc_experiment_df = dcc_experiment_df.drop(
            &#34;complete_derivations.unique_id&#34;,
            &#34;unique_id_result&#34;,
            &#34;pipelineKey&#34;,
            &#34;procedureKey&#34;,
            &#34;parameterKey&#34;,
            &#34;results&#34;,
        )
        dcc_experiment_df.write.parquet(output_path)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>luigi.contrib.spark.PySparkTask</li>
<li>luigi.contrib.spark.SparkSubmitTask</li>
<li>luigi.contrib.external_program.ExternalProgramTask</li>
<li>luigi.task.Task</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator">ExperimentParameterDerivator</a></li>
<li><a title="impc_etl.jobs.transform.experiment_parameter_derivator.LineParameterDerivator" href="#impc_etl.jobs.transform.experiment_parameter_derivator.LineParameterDerivator">LineParameterDerivator</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.dcc_xml_path"><code class="name">var <span class="ident">dcc_xml_path</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.experiment_level"><code class="name">var <span class="ident">experiment_level</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.imits_colonies_tsv_path"><code class="name">var <span class="ident">imits_colonies_tsv_path</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.output_path"><code class="name">var <span class="ident">output_path</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.app_options"><code class="name flex">
<span>def <span class="ident">app_options</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Subclass this method to map your task parameters to the app's arguments</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def app_options(self):
    return [self.input()[0].path, self.input()[1].path, self.output().path]</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>self, sc, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Called by the pyspark_runner with a SparkContext and any arguments returned by <code>app_options()</code></p>
<p>:param sc: SparkContext
:param args: arguments list</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main(self, sc, *args):
    spark = SparkSession(sc)
    experiment_parquet_path = args[0]
    pipeline_parquet_path = args[1]
    output_path = args[2]
    dcc_experiment_df = spark.read.parquet(experiment_parquet_path)
    impress_df = spark.read.parquet(pipeline_parquet_path)
    europhenome_derivations_json = spark.sparkContext.parallelize(
        Constants.EUROPHENOME_DERIVATIONS
    )
    europhenome_derivations_df = spark.read.json(europhenome_derivations_json)
    europhenome_derivations_df = europhenome_derivations_df.alias(&#34;europhenome&#34;)

    europhenome_parameters = [
        derivation[&#34;europhenomeParameter&#34;]
        for derivation in Constants.EUROPHENOME_DERIVATIONS
    ]

    # Filter impress DataFrame to get only the derived parameters, filtering out archive and unimplemented
    derived_parameters: DataFrame = (
        impress_df.where(
            (
                (impress_df[&#34;parameter.isDerived&#34;] == True)
                &amp; (impress_df[&#34;parameter.isDeprecated&#34;] == False)
                &amp; (~impress_df[&#34;parameter.derivation&#34;].contains(&#34;archived&#34;))
                &amp; (~impress_df[&#34;parameter.derivation&#34;].contains(&#34;unimplemented&#34;))
            )
            | (impress_df[&#34;parameter.parameterKey&#34;].isin(europhenome_parameters))
        )
        .where(
            ~impress_df[&#34;parameter.parameterKey&#34;].isin(
                Constants.DERIVED_PARAMETER_BANLIST
            )
        )
        .select(
            &#34;pipelineKey&#34;,
            &#34;procedure.procedureKey&#34;,
            &#34;parameter.parameterKey&#34;,
            &#34;parameter.derivation&#34;,
            &#34;parameter.type&#34;,
            &#34;unitName&#34;,
        )
        .dropDuplicates()
    )

    derived_parameters = derived_parameters.join(
        europhenome_derivations_df,
        col(&#34;parameterKey&#34;) == europhenome_derivations_df[&#34;europhenomeParameter&#34;],
        &#34;left_outer&#34;,
    )
    derived_parameters = derived_parameters.withColumn(
        &#34;derivation&#34;,
        when(
            col(&#34;europhenomeDerivation&#34;).isNotNull(), col(&#34;europhenomeDerivation&#34;)
        ).otherwise(col(&#34;derivation&#34;)),
    )
    derived_parameters = derived_parameters.drop(&#34;europhenome.*&#34;)

    # Use a Python UDF to extract the keys of the parameters involved in the derivations as a list
    extract_parameters_from_derivation_udf = udf(
        extract_parameters_from_derivation, ArrayType(StringType())
    )

    derived_parameters = derived_parameters.withColumn(
        &#34;derivationInputs&#34;, extract_parameters_from_derivation_udf(&#34;derivation&#34;)
    )

    # Explode the derivation inputs
    derived_parameters_ex = derived_parameters.withColumn(
        &#34;derivationInput&#34;, explode(&#34;derivationInputs&#34;)
    ).select(
        &#34;pipelineKey&#34;,
        &#34;procedureKey&#34;,
        &#34;parameterKey&#34;,
        &#34;derivation&#34;,
        &#34;derivationInput&#34;,
    )

    # Compute the derivation inputs for simple, procedure and series parameters
    # Each input is has the form &lt;PARAMETER_KEY&gt;$&lt;PARAMETER_VALUE&gt;
    # If the parameter has increments the inputs will have the form
    # &lt;PARAMETER_KEY&gt;$INCREMENT_1$&lt;PARAMETER_VALUE&gt;|INCREMENT_1$&lt;PARAMETER_VALUE&gt;
    experiments_simple = _get_inputs_by_parameter_type(
        dcc_experiment_df, derived_parameters_ex, &#34;simpleParameter&#34;
    )
    experiments_metadata = _get_inputs_by_parameter_type(
        dcc_experiment_df, derived_parameters_ex, &#34;procedureMetadata&#34;
    )
    experiments_vs_derivations = experiments_simple.union(experiments_metadata)

    if has_column(dcc_experiment_df, &#34;seriesParameter&#34;):
        experiments_series = _get_inputs_by_parameter_type(
            dcc_experiment_df, derived_parameters_ex, &#34;seriesParameter&#34;
        )
        experiments_vs_derivations = experiments_vs_derivations.union(
            experiments_series
        )
    # Collect the derivation inputs in a comma separated list
    experiments_vs_derivations = experiments_vs_derivations.groupby(
        &#34;unique_id&#34;, &#34;pipelineKey&#34;, &#34;procedureKey&#34;, &#34;parameterKey&#34;, &#34;derivation&#34;
    ).agg(
        concat_ws(
            &#34;,&#34;, collect_list(experiments_vs_derivations[&#34;derivationInput&#34;])
        ).alias(&#34;derivationInputStr&#34;)
    )

    experiments_vs_derivations = experiments_vs_derivations.join(
        derived_parameters.drop(&#34;derivation&#34;),
        [&#34;pipelineKey&#34;, &#34;procedureKey&#34;, &#34;parameterKey&#34;],
    )

    # Check if the experiment contains all the parameter values to perform the derivation
    experiments_vs_derivations = experiments_vs_derivations.withColumn(
        &#34;derivationInput&#34;, explode(&#34;derivationInputs&#34;)
    )
    experiments_vs_derivations = experiments_vs_derivations.withColumn(
        &#34;isPresent&#34;,
        when(
            col(&#34;derivationInputStr&#34;).contains(col(&#34;derivationInput&#34;)), 1
        ).otherwise(0),
    )
    experiments_vs_derivations = experiments_vs_derivations.groupBy(
        [
            &#34;unique_id&#34;,
            &#34;pipelineKey&#34;,
            &#34;procedureKey&#34;,
            &#34;parameterKey&#34;,
            &#34;derivationInputStr&#34;,
            &#34;derivationInputs&#34;,
            &#34;derivation&#34;,
        ]
    ).agg(sum(&#34;isPresent&#34;).alias(&#34;presentColumns&#34;))

    experiments_vs_derivations = experiments_vs_derivations.withColumn(
        &#34;isComplete&#34;,
        when((size(col(&#34;derivationInputs&#34;)) == col(&#34;presentColumns&#34;)), lit(True))
        .when(
            (
                (col(&#34;derivation&#34;).contains(&#34;retinaCombined&#34;))
                | (col(&#34;derivation&#34;).contains(&#34;ifElse&#34;))
            )
            &amp; (size(col(&#34;derivationInputs&#34;)) &gt; 0),
            lit(True),
        )
        .otherwise(lit(False)),
    )
    experiments_vs_derivations = experiments_vs_derivations.withColumn(
        &#34;derivationInputStr&#34;, concat(&#34;derivation&#34;, lit(&#34;;&#34;), &#34;derivationInputStr&#34;)
    )
    spark.udf.registerJavaFunction(
        &#34;phenodcc_derivator&#34;,
        &#34;org.mousephenotype.dcc.derived.parameters.SparkDerivator&#34;,
        StringType(),
    )

    results_df = experiments_vs_derivations.select(
        &#34;unique_id&#34;,
        &#34;pipelineKey&#34;,
        &#34;procedureKey&#34;,
        &#34;parameterKey&#34;,
        &#34;presentColumns&#34;,
        &#34;isComplete&#34;,
        &#34;derivationInputStr&#34;,
    ).dropDuplicates()
    results_df = results_df.withColumn(
        &#34;result&#34;,
        when(
            (col(&#34;isComplete&#34;) == True),
            expr(&#34;phenodcc_derivator(derivationInputStr)&#34;),
        ).otherwise(lit(None)),
    )

    # Filtering not valid numeric values
    results_df = results_df.withColumn(
        &#34;result&#34;,
        when(
            (col(&#34;result&#34;) == &#34;NaN&#34;)
            | (col(&#34;result&#34;) == &#34;Infinity&#34;)
            | (col(&#34;result&#34;) == &#34;-Infinity&#34;),
            lit(None),
        ).otherwise(col(&#34;result&#34;)),
    )
    results_df = results_df.where(col(&#34;result&#34;).isNotNull())
    results_df = results_df.join(
        derived_parameters, [&#34;pipelineKey&#34;, &#34;procedureKey&#34;, &#34;parameterKey&#34;]
    )

    result_schema_fields = [
        results_df[&#34;parameterKey&#34;].alias(&#34;_parameterID&#34;),
        results_df[&#34;unitName&#34;].alias(&#34;_unit&#34;),
        lit(None).cast(StringType()).alias(&#34;parameterStatus&#34;),
        results_df[&#34;result&#34;].alias(&#34;value&#34;),
    ]
    if self.experiment_level == &#34;experiment&#34;:
        result_schema_fields.insert(
            1, lit(None).cast(LongType()).alias(&#34;_sequenceID&#34;)
        )
    elif has_column(dcc_experiment_df, &#34;simpleParameter._VALUE&#34;):
        result_schema_fields.insert(0, lit(None).cast(StringType()).alias(&#34;_VALUE&#34;))
    result_struct = struct(*result_schema_fields)
    results_df = results_df.groupBy(&#34;unique_id&#34;, &#34;pipelineKey&#34;, &#34;procedureKey&#34;).agg(
        collect_list(result_struct).alias(&#34;results&#34;)
    )
    results_df = results_df.withColumnRenamed(&#34;unique_id&#34;, &#34;unique_id_result&#34;)

    dcc_experiment_df = dcc_experiment_df.join(
        results_df,
        (dcc_experiment_df[&#34;unique_id&#34;] == results_df[&#34;unique_id_result&#34;])
        &amp; (dcc_experiment_df[&#34;_procedureID&#34;] == results_df[&#34;procedureKey&#34;])
        &amp; (dcc_experiment_df[&#34;_pipeline&#34;] == results_df[&#34;pipelineKey&#34;]),
        &#34;left_outer&#34;,
    )

    simple_parameter_type = None

    for c_type in dcc_experiment_df.dtypes:
        if c_type[0] == &#34;simpleParameter&#34;:
            simple_parameter_type = c_type[1]
            break
    merge_simple_parameters = udf(_merge_simple_parameters, simple_parameter_type)
    dcc_experiment_df = dcc_experiment_df.withColumn(
        &#34;simpleParameter&#34;,
        when(
            (col(&#34;results&#34;).isNotNull() &amp; col(&#34;simpleParameter&#34;).isNotNull()),
            merge_simple_parameters(col(&#34;simpleParameter&#34;), col(&#34;results&#34;)),
        )
        .when(col(&#34;simpleParameter&#34;).isNull(), col(&#34;results&#34;))
        .otherwise(col(&#34;simpleParameter&#34;)),
    )
    dcc_experiment_df = dcc_experiment_df.drop(
        &#34;complete_derivations.unique_id&#34;,
        &#34;unique_id_result&#34;,
        &#34;pipelineKey&#34;,
        &#34;procedureKey&#34;,
        &#34;parameterKey&#34;,
        &#34;results&#34;,
    )
    dcc_experiment_df.write.parquet(output_path)</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.output"><code class="name flex">
<span>def <span class="ident">output</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>The output that this Task produces.</p>
<p>The output of the Task determines if the Task needs to be run&ndash;the task
is considered finished iff the outputs all exist. Subclasses should
override this method to return a single :py:class:<code>Target</code> or a list of
:py:class:<code>Target</code> instances.</p>
<p>Implementation note
If running multiple workers, the output must be a resource that is accessible
by all workers, such as a DFS or database. Otherwise, workers might compute
the same output since they don't see the work done by other workers.</p>
<p>See :ref:<code>Task.output</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def output(self):
    return ImpcConfig().get_target(
        f&#34;{self.output_path}{self.experiment_level}_derived_parquet&#34;
    )</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<div style="max-width: 300px; text-align: center">
<img src="https://www.mousephenotype.org/wp-content/themes/impc/images/IMPC_10_YEAR_Logo.svg" alt="IMPC Logo">
</div>
<h1 style="text-align: center; max-width: 300px;">IMPC ETL</h1>
<h2 style="text-align: center; max-width: 300px;">Reference Documentation</h2>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="impc_etl.jobs.transform" href="index.html">impc_etl.jobs.transform</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator">ExperimentParameterDerivator</a></code></h4>
<ul class="">
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator.experiment_level" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator.experiment_level">experiment_level</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator.name" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator.name">name</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator.requires" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ExperimentParameterDerivator.requires">requires</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.LineParameterDerivator" href="#impc_etl.jobs.transform.experiment_parameter_derivator.LineParameterDerivator">LineParameterDerivator</a></code></h4>
<ul class="">
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.LineParameterDerivator.experiment_level" href="#impc_etl.jobs.transform.experiment_parameter_derivator.LineParameterDerivator.experiment_level">experiment_level</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.LineParameterDerivator.name" href="#impc_etl.jobs.transform.experiment_parameter_derivator.LineParameterDerivator.name">name</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.LineParameterDerivator.requires" href="#impc_etl.jobs.transform.experiment_parameter_derivator.LineParameterDerivator.requires">requires</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator">ParameterDerivator</a></code></h4>
<ul class="">
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.app_options" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.app_options">app_options</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.dcc_xml_path" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.dcc_xml_path">dcc_xml_path</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.experiment_level" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.experiment_level">experiment_level</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.imits_colonies_tsv_path" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.imits_colonies_tsv_path">imits_colonies_tsv_path</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.main" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.main">main</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.output" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.output">output</a></code></li>
<li><code><a title="impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.output_path" href="#impc_etl.jobs.transform.experiment_parameter_derivator.ParameterDerivator.output_path">output_path</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p><span></span></p>
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>