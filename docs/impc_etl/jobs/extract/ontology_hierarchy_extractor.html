<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>impc_etl.jobs.extract.ontology_hierarchy_extractor API documentation</title>
<meta name="description" content="IMPC Ontology Hierarchy Extraction task. It takes in a set of ontologies and returns them in a parquet file that
represents the hierarchical relations …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>impc_etl.jobs.extract.ontology_hierarchy_extractor</code></h1>
</header>
<section id="section-intro">
<p>IMPC Ontology Hierarchy Extraction task. It takes in a set of ontologies and returns them in a parquet file that
represents the hierarchical relations between the terms on those ontologies.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
    IMPC Ontology Hierarchy Extraction task. It takes in a set of ontologies and returns them in a parquet file that
    represents the hierarchical relations between the terms on those ontologies.
&#34;&#34;&#34;
import unicodedata
from typing import Dict, Iterable, List, Any

import luigi
import pronto
from luigi.contrib.spark import PySparkTask
from pronto import Ontology, Term, Relationship
from pyspark import SparkContext
from pyspark.sql import DataFrame, SparkSession
from pyspark.sql.types import StructType, StructField, StringType, ArrayType

from impc_etl.workflow.config import ImpcConfig


class OntologyTermHierarchyExtractor(PySparkTask):
    &#34;&#34;&#34;
    PySpark Task class to extract the hierarchical relations between terms for the ontologies: MPATH, MA, EMAPA and MP.
    The main goal of this task is to assign to any ontology term a list of:

    - direct children
    - direct parents
    - top level terms
    - intermediate terms (i.e. terms between the given term and the top level ones)
    - synonyms and definitions for all the related terms
    &#34;&#34;&#34;

    #: Name of the Spark task
    name = &#34;IMPC_Ontology_Term_Hierarchy_Extractor&#34;

    #: Path to the directory containing OBO files for MA, MPATH, EMAPA and MP.
    obo_ontology_input_path: luigi.Parameter = luigi.Parameter()

    #: Path of the output directory where ethe new parquet file will be generated.
    output_path: luigi.Parameter = luigi.Parameter()

    #: List on ontologies to process with their corresponding top level terms
    ONTOLOGIES: List[Dict] = [
        {&#34;id&#34;: &#34;mpath&#34;, &#34;format&#34;: &#34;obo&#34;, &#34;top_level_terms&#34;: []},
        {
            &#34;id&#34;: &#34;mp&#34;,
            &#34;format&#34;: &#34;obo&#34;,
            &#34;top_level_terms&#34;: [
                &#34;MP:0010768&#34;,
                &#34;MP:0002873&#34;,
                &#34;MP:0001186&#34;,
                &#34;MP:0003631&#34;,
                &#34;MP:0005367&#34;,
                &#34;MP:0005369&#34;,
                &#34;MP:0005370&#34;,
                &#34;MP:0005371&#34;,
                &#34;MP:0005377&#34;,
                &#34;MP:0005378&#34;,
                &#34;MP:0005375&#34;,
                &#34;MP:0005376&#34;,
                &#34;MP:0005379&#34;,
                &#34;MP:0005380&#34;,
                &#34;MP:0005381&#34;,
                &#34;MP:0005384&#34;,
                &#34;MP:0005385&#34;,
                &#34;MP:0005382&#34;,
                &#34;MP:0005388&#34;,
                &#34;MP:0005389&#34;,
                &#34;MP:0005386&#34;,
                &#34;MP:0005387&#34;,
                &#34;MP:0005391&#34;,
                &#34;MP:0005390&#34;,
                &#34;MP:0005394&#34;,
                &#34;MP:0005397&#34;,
                &#34;MP:0010771&#34;,
            ],
        },
        {
            &#34;id&#34;: &#34;ma&#34;,
            &#34;format&#34;: &#34;obo&#34;,
            &#34;top_level_terms&#34;: [
                &#34;MA:0000004&#34;,
                &#34;MA:0000007&#34;,
                &#34;MA:0000009&#34;,
                &#34;MA:0000010&#34;,
                &#34;MA:0000012&#34;,
                &#34;MA:0000014&#34;,
                &#34;MA:0000016&#34;,
                &#34;MA:0000017&#34;,
                &#34;MA:0000325&#34;,
                &#34;MA:0000326&#34;,
                &#34;MA:0000327&#34;,
                &#34;MA:0002411&#34;,
                &#34;MA:0002418&#34;,
                &#34;MA:0002431&#34;,
                &#34;MA:0002711&#34;,
                &#34;MA:0002887&#34;,
                &#34;MA:0002405&#34;,
            ],
        },
        {
            &#34;id&#34;: &#34;emapa&#34;,
            &#34;format&#34;: &#34;obo&#34;,
            &#34;top_level_terms&#34;: [
                &#34;EMAPA:16104&#34;,
                &#34;EMAPA:16192&#34;,
                &#34;EMAPA:16246&#34;,
                &#34;EMAPA:16405&#34;,
                &#34;EMAPA:16469&#34;,
                &#34;EMAPA:16727&#34;,
                &#34;EMAPA:16748&#34;,
                &#34;EMAPA:16840&#34;,
                &#34;EMAPA:17524&#34;,
                &#34;EMAPA:31858&#34;,
            ],
        },
        # {&#34;id&#34;: &#34;efo&#34;, &#34;top_level_terms&#34;: []},
        # {&#34;id&#34;: &#34;emap&#34;, &#34;top_level_terms&#34;: []},
        # {&#34;id&#34;: &#34;pato&#34;, &#34;top_level_terms&#34;: []},
    ]

    #: Schema of the resulting parquet file
    ONTOLOGY_SCHEMA: StructType = StructType(
        [
            StructField(&#34;id&#34;, StringType(), True),
            StructField(&#34;term&#34;, StringType(), True),
            StructField(&#34;definition&#34;, StringType(), True),
            StructField(&#34;synonyms&#34;, ArrayType(StringType()), True),
            StructField(&#34;alt_ids&#34;, ArrayType(StringType()), True),
            StructField(&#34;child_ids&#34;, ArrayType(StringType()), True),
            StructField(&#34;child_terms&#34;, ArrayType(StringType()), True),
            StructField(&#34;child_definitions&#34;, ArrayType(StringType()), True),
            StructField(&#34;child_term_synonyms&#34;, ArrayType(StringType()), True),
            StructField(&#34;parent_ids&#34;, ArrayType(StringType()), True),
            StructField(&#34;parent_terms&#34;, ArrayType(StringType()), True),
            StructField(&#34;parent_definitions&#34;, ArrayType(StringType()), True),
            StructField(&#34;parent_term_synonyms&#34;, ArrayType(StringType()), True),
            StructField(&#34;intermediate_ids&#34;, ArrayType(StringType()), True),
            StructField(&#34;intermediate_terms&#34;, ArrayType(StringType()), True),
            StructField(&#34;intermediate_definitions&#34;, ArrayType(StringType()), True),
            StructField(&#34;intermediate_term_synonyms&#34;, ArrayType(StringType()), True),
            StructField(&#34;top_level_ids&#34;, ArrayType(StringType()), True),
            StructField(&#34;top_level_terms&#34;, ArrayType(StringType()), True),
            StructField(&#34;top_level_definitions&#34;, ArrayType(StringType()), True),
            StructField(&#34;top_level_synonyms&#34;, ArrayType(StringType()), True),
            StructField(&#34;top_level_term_id&#34;, ArrayType(StringType()), True),
        ]
    )

    def output(self):
        &#34;&#34;&#34;
        Returns the full parquet path as an output for the Luigi Task
        (e.g. impc/dr15.2/parquet/impc_ontology_term_hierarchy_parquet)
        &#34;&#34;&#34;
        return ImpcConfig().get_target(
            f&#34;{self.output_path}impc_ontology_term_hierarchy_parquet&#34;
        )

    def app_options(self):
        &#34;&#34;&#34;
        Generates the options pass to the PySpark job
        &#34;&#34;&#34;
        return [
            self.obo_ontology_input_path,
            self.output().path,
        ]

    def main(self, sc: SparkContext, *args: Any):
        &#34;&#34;&#34;
        DCC Extractor job runner
        &#34;&#34;&#34;
        input_path = args[0]
        output_path = args[1]

        spark = SparkSession(sc)
        ontology_df = self.extract_ontology_terms(spark, input_path)
        ontology_df.write.mode(&#34;overwrite&#34;).parquet(output_path)

    def extract_ontology_terms(
        self, spark_session: SparkSession, ontologies_path: str
    ) -&gt; DataFrame:
        &#34;&#34;&#34;
        Takes in a spark session and the path containing cached OBO files and returns
        a DataFrame that represents Ontology terms hierarchical relationships.
        &#34;&#34;&#34;

        # List of ontology terms
        ontology_terms = []

        # This process can only be performed on local or client mode
        if ImpcConfig().deploy_mode in [&#34;local&#34;, &#34;client&#34;]:
            for ontology_desc in self.ONTOLOGIES:
                print(f&#34;Processing {ontology_desc[&#39;id&#39;]}.{ontology_desc[&#39;format&#39;]}&#34;)

                # Get the OBO file from the directory if MPATH otherwise get it from OBO foundry
                if ontology_desc[&#34;id&#34;] == &#34;mpath&#34;:
                    ontology: Ontology = Ontology(ontologies_path + &#34;mpath.obo&#34;)
                else:
                    ontology: Ontology = pronto.Ontology.from_obo_library(
                        f&#34;{ontology_desc[&#39;id&#39;]}.{ontology_desc[&#39;format&#39;]}&#34;
                    )

                part_of_rel: Relationship = None

                # Find the part_of relationship on the current loaded ontology
                for rel in ontology.relationships():
                    if rel.id == &#34;part_of&#34;:
                        part_of_rel = rel
                        break

                # If a part_of relationship is found, compute the hierarchy of terms using it
                if part_of_rel is not None:
                    part_of_rel.transitive = False
                    print(&#34;Starting to compute super classes from part_of&#34;)
                    for term in ontology.terms():
                        for super_part_term in term.objects(part_of_rel):
                            if super_part_term.id in ontology.keys():
                                term.superclasses().add(super_part_term)
                    print(&#34;Finished to compute super classes from part_of&#34;)

                # Get the set of ancestors for the top level terms
                top_level_terms = [
                    ontology[term] for term in ontology_desc[&#34;top_level_terms&#34;]
                ]
                top_level_ancestors = []
                for top_level_term in top_level_terms:
                    top_level_ancestors.extend(
                        top_level_term.superclasses(with_self=False)
                    )
                top_level_ancestors = set(top_level_ancestors)

                # Iterate over the ontology terms and to get the hierarchy between them and the top level terms
                ontology_terms += [
                    self._parse_ontology_term(
                        term, top_level_terms, top_level_ancestors, part_of_rel
                    )
                    for term in ontology.terms()
                    if term.name is not None
                ]
                print(
                    f&#34;Finished processing {ontology_desc[&#39;id&#39;]}.{ontology_desc[&#39;format&#39;]}&#34;
                )

        # Transform the list of dictionaries representing terms to JSON
        ontology_terms_json = spark_session.sparkContext.parallelize(ontology_terms)

        # Read the JSON RDD to a Spark DataFrame so it can be written to disk as Parquet
        ontology_terms_df = spark_session.read.json(
            ontology_terms_json, schema=self.ONTOLOGY_SCHEMA, mode=&#34;FAILFAST&#34;
        )
        return ontology_terms_df

    def _parse_ontology_term(
        self,
        ontology_term: Term,
        top_level_terms,
        top_level_ancestors,
        part_of_rel: Relationship,
    ) -&gt; Dict:
        &#34;&#34;&#34;
        Takes in an ontology term, a list of top level terms, a list of top level ancestors
        (i.e. the ancestors of the top level terms),
        the relationship used to convey hierarchy and returns a list of dictionaries with all the hierarchical
        relationships between the terms and the top level terms.
        &#34;&#34;&#34;

        # Gather the direct children of the term
        children = [
            child_term for child_term in ontology_term.subclasses(1, with_self=False)
        ]

        # Get the direct parents of the term
        parents = [
            parent_term
            for parent_term in ontology_term.superclasses(1, with_self=False)
        ]

        # Get all the ancestors of the term
        ancestors = [
            ancestor_term
            for ancestor_term in ontology_term.superclasses(with_self=False)
        ]

        # Get all the ancestors based on the part_of relationship instead of relying on the is_a relationship
        if part_of_rel is not None:
            ancestors.extend(
                [ancestor_term for ancestor_term in ontology_term.objects(part_of_rel)]
            )

        # Get the term top level terms by intersecting its ancestors with the ontology top level terms
        term_top_level_terms = set(top_level_terms).intersection(set(ancestors))

        # Determine the intermediate terms
        intermediate_terms = (
            set(ancestors)
            .difference(set(top_level_terms))
            .difference(top_level_ancestors)
        )
        # Builds and returns the term dictionary containing all the related terms information
        return {
            &#34;id&#34;: ontology_term.id,
            &#34;term&#34;: self._parse_text(ontology_term.name),
            &#34;definition&#34;: self._parse_text(ontology_term.definition)
            if ontology_term.definition is not None
            else &#34;null&#34;,
            &#34;synonyms&#34;: [
                self._parse_text(synonym.description)
                for synonym in ontology_term.synonyms
                if synonym.type is &#34;EXACT&#34;
            ],
            &#34;alt_ids&#34;: list(ontology_term.alternate_ids),
            &#34;child_ids&#34;: [child_term.id for child_term in children],
            &#34;child_terms&#34;: [
                self._parse_text(child_term.name) for child_term in children
            ],
            &#34;child_definitions&#34;: [
                self._parse_text(child_term.definition)
                for child_term in children
                if child_term.definition is not None
            ],
            &#34;child_term_synonyms&#34;: self._get_synonym_list(children),
            &#34;parent_ids&#34;: [parent_term.id for parent_term in parents],
            &#34;parent_terms&#34;: [
                self._parse_text(parent_term.name) for parent_term in parents
            ],
            &#34;parent_definitions&#34;: [
                self._parse_text(parent_term.definition)
                for parent_term in parents
                if parent_term.definition is not None
            ],
            &#34;parent_term_synonyms&#34;: self._get_synonym_list(parents),
            &#34;intermediate_ids&#34;: [
                intermediate_term.id for intermediate_term in intermediate_terms
            ],
            &#34;intermediate_terms&#34;: [
                self._parse_text(intermediate_term.name)
                for intermediate_term in intermediate_terms
            ],
            &#34;intermediate_definitions&#34;: [
                self._parse_text(intermediate_term.definition)
                for intermediate_term in intermediate_terms
                if intermediate_term.definition is not None
            ],
            &#34;intermediate_term_synonyms&#34;: self._get_synonym_list(intermediate_terms),
            &#34;top_level_ids&#34;: [
                term_top_level_term.id for term_top_level_term in term_top_level_terms
            ],
            &#34;top_level_terms&#34;: [
                self._parse_text(term_top_level_term.name)
                for term_top_level_term in term_top_level_terms
            ],
            &#34;top_level_definitions&#34;: [
                self._parse_text(term_top_level_term.definition)
                for term_top_level_term in term_top_level_terms
                if term_top_level_term.definition is not None
            ],
            &#34;top_level_synonyms&#34;: self._get_synonym_list(term_top_level_terms),
            &#34;top_level_term_id&#34;: [
                f&#34;{term_top_level_term.id}___{self._parse_text(term_top_level_term.name)}&#34;
                for term_top_level_term in term_top_level_terms
            ],
        }

    def _get_synonym_list(self, terms: Iterable[Term]):
        &#34;&#34;&#34;
        Takes in a list of Terms and returns the list of synonyms for the given terms.
        &#34;&#34;&#34;
        flat_list = []
        for term in terms:
            for synonym in term.synonyms:
                flat_list.append(self._parse_text(synonym.description))
        return flat_list

    def _parse_text(self, definition: bytes):
        &#34;&#34;&#34;
        Parse an OBO definition text an return a valid Python str.
        &#34;&#34;&#34;
        if definition is None:
            return None
        return unicodedata.normalize(
            &#34;NFKD&#34;, definition.encode(&#34;iso-8859-1&#34;).decode(&#34;utf-8&#34;)
        )</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor"><code class="flex name class">
<span>class <span class="ident">OntologyTermHierarchyExtractor</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>PySpark Task class to extract the hierarchical relations between terms for the ontologies: MPATH, MA, EMAPA and MP.
The main goal of this task is to assign to any ontology term a list of:</p>
<ul>
<li>direct children</li>
<li>direct parents</li>
<li>top level terms</li>
<li>intermediate terms (i.e. terms between the given term and the top level ones)</li>
<li>synonyms and definitions for all the related terms</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class OntologyTermHierarchyExtractor(PySparkTask):
    &#34;&#34;&#34;
    PySpark Task class to extract the hierarchical relations between terms for the ontologies: MPATH, MA, EMAPA and MP.
    The main goal of this task is to assign to any ontology term a list of:

    - direct children
    - direct parents
    - top level terms
    - intermediate terms (i.e. terms between the given term and the top level ones)
    - synonyms and definitions for all the related terms
    &#34;&#34;&#34;

    #: Name of the Spark task
    name = &#34;IMPC_Ontology_Term_Hierarchy_Extractor&#34;

    #: Path to the directory containing OBO files for MA, MPATH, EMAPA and MP.
    obo_ontology_input_path: luigi.Parameter = luigi.Parameter()

    #: Path of the output directory where ethe new parquet file will be generated.
    output_path: luigi.Parameter = luigi.Parameter()

    #: List on ontologies to process with their corresponding top level terms
    ONTOLOGIES: List[Dict] = [
        {&#34;id&#34;: &#34;mpath&#34;, &#34;format&#34;: &#34;obo&#34;, &#34;top_level_terms&#34;: []},
        {
            &#34;id&#34;: &#34;mp&#34;,
            &#34;format&#34;: &#34;obo&#34;,
            &#34;top_level_terms&#34;: [
                &#34;MP:0010768&#34;,
                &#34;MP:0002873&#34;,
                &#34;MP:0001186&#34;,
                &#34;MP:0003631&#34;,
                &#34;MP:0005367&#34;,
                &#34;MP:0005369&#34;,
                &#34;MP:0005370&#34;,
                &#34;MP:0005371&#34;,
                &#34;MP:0005377&#34;,
                &#34;MP:0005378&#34;,
                &#34;MP:0005375&#34;,
                &#34;MP:0005376&#34;,
                &#34;MP:0005379&#34;,
                &#34;MP:0005380&#34;,
                &#34;MP:0005381&#34;,
                &#34;MP:0005384&#34;,
                &#34;MP:0005385&#34;,
                &#34;MP:0005382&#34;,
                &#34;MP:0005388&#34;,
                &#34;MP:0005389&#34;,
                &#34;MP:0005386&#34;,
                &#34;MP:0005387&#34;,
                &#34;MP:0005391&#34;,
                &#34;MP:0005390&#34;,
                &#34;MP:0005394&#34;,
                &#34;MP:0005397&#34;,
                &#34;MP:0010771&#34;,
            ],
        },
        {
            &#34;id&#34;: &#34;ma&#34;,
            &#34;format&#34;: &#34;obo&#34;,
            &#34;top_level_terms&#34;: [
                &#34;MA:0000004&#34;,
                &#34;MA:0000007&#34;,
                &#34;MA:0000009&#34;,
                &#34;MA:0000010&#34;,
                &#34;MA:0000012&#34;,
                &#34;MA:0000014&#34;,
                &#34;MA:0000016&#34;,
                &#34;MA:0000017&#34;,
                &#34;MA:0000325&#34;,
                &#34;MA:0000326&#34;,
                &#34;MA:0000327&#34;,
                &#34;MA:0002411&#34;,
                &#34;MA:0002418&#34;,
                &#34;MA:0002431&#34;,
                &#34;MA:0002711&#34;,
                &#34;MA:0002887&#34;,
                &#34;MA:0002405&#34;,
            ],
        },
        {
            &#34;id&#34;: &#34;emapa&#34;,
            &#34;format&#34;: &#34;obo&#34;,
            &#34;top_level_terms&#34;: [
                &#34;EMAPA:16104&#34;,
                &#34;EMAPA:16192&#34;,
                &#34;EMAPA:16246&#34;,
                &#34;EMAPA:16405&#34;,
                &#34;EMAPA:16469&#34;,
                &#34;EMAPA:16727&#34;,
                &#34;EMAPA:16748&#34;,
                &#34;EMAPA:16840&#34;,
                &#34;EMAPA:17524&#34;,
                &#34;EMAPA:31858&#34;,
            ],
        },
        # {&#34;id&#34;: &#34;efo&#34;, &#34;top_level_terms&#34;: []},
        # {&#34;id&#34;: &#34;emap&#34;, &#34;top_level_terms&#34;: []},
        # {&#34;id&#34;: &#34;pato&#34;, &#34;top_level_terms&#34;: []},
    ]

    #: Schema of the resulting parquet file
    ONTOLOGY_SCHEMA: StructType = StructType(
        [
            StructField(&#34;id&#34;, StringType(), True),
            StructField(&#34;term&#34;, StringType(), True),
            StructField(&#34;definition&#34;, StringType(), True),
            StructField(&#34;synonyms&#34;, ArrayType(StringType()), True),
            StructField(&#34;alt_ids&#34;, ArrayType(StringType()), True),
            StructField(&#34;child_ids&#34;, ArrayType(StringType()), True),
            StructField(&#34;child_terms&#34;, ArrayType(StringType()), True),
            StructField(&#34;child_definitions&#34;, ArrayType(StringType()), True),
            StructField(&#34;child_term_synonyms&#34;, ArrayType(StringType()), True),
            StructField(&#34;parent_ids&#34;, ArrayType(StringType()), True),
            StructField(&#34;parent_terms&#34;, ArrayType(StringType()), True),
            StructField(&#34;parent_definitions&#34;, ArrayType(StringType()), True),
            StructField(&#34;parent_term_synonyms&#34;, ArrayType(StringType()), True),
            StructField(&#34;intermediate_ids&#34;, ArrayType(StringType()), True),
            StructField(&#34;intermediate_terms&#34;, ArrayType(StringType()), True),
            StructField(&#34;intermediate_definitions&#34;, ArrayType(StringType()), True),
            StructField(&#34;intermediate_term_synonyms&#34;, ArrayType(StringType()), True),
            StructField(&#34;top_level_ids&#34;, ArrayType(StringType()), True),
            StructField(&#34;top_level_terms&#34;, ArrayType(StringType()), True),
            StructField(&#34;top_level_definitions&#34;, ArrayType(StringType()), True),
            StructField(&#34;top_level_synonyms&#34;, ArrayType(StringType()), True),
            StructField(&#34;top_level_term_id&#34;, ArrayType(StringType()), True),
        ]
    )

    def output(self):
        &#34;&#34;&#34;
        Returns the full parquet path as an output for the Luigi Task
        (e.g. impc/dr15.2/parquet/impc_ontology_term_hierarchy_parquet)
        &#34;&#34;&#34;
        return ImpcConfig().get_target(
            f&#34;{self.output_path}impc_ontology_term_hierarchy_parquet&#34;
        )

    def app_options(self):
        &#34;&#34;&#34;
        Generates the options pass to the PySpark job
        &#34;&#34;&#34;
        return [
            self.obo_ontology_input_path,
            self.output().path,
        ]

    def main(self, sc: SparkContext, *args: Any):
        &#34;&#34;&#34;
        DCC Extractor job runner
        &#34;&#34;&#34;
        input_path = args[0]
        output_path = args[1]

        spark = SparkSession(sc)
        ontology_df = self.extract_ontology_terms(spark, input_path)
        ontology_df.write.mode(&#34;overwrite&#34;).parquet(output_path)

    def extract_ontology_terms(
        self, spark_session: SparkSession, ontologies_path: str
    ) -&gt; DataFrame:
        &#34;&#34;&#34;
        Takes in a spark session and the path containing cached OBO files and returns
        a DataFrame that represents Ontology terms hierarchical relationships.
        &#34;&#34;&#34;

        # List of ontology terms
        ontology_terms = []

        # This process can only be performed on local or client mode
        if ImpcConfig().deploy_mode in [&#34;local&#34;, &#34;client&#34;]:
            for ontology_desc in self.ONTOLOGIES:
                print(f&#34;Processing {ontology_desc[&#39;id&#39;]}.{ontology_desc[&#39;format&#39;]}&#34;)

                # Get the OBO file from the directory if MPATH otherwise get it from OBO foundry
                if ontology_desc[&#34;id&#34;] == &#34;mpath&#34;:
                    ontology: Ontology = Ontology(ontologies_path + &#34;mpath.obo&#34;)
                else:
                    ontology: Ontology = pronto.Ontology.from_obo_library(
                        f&#34;{ontology_desc[&#39;id&#39;]}.{ontology_desc[&#39;format&#39;]}&#34;
                    )

                part_of_rel: Relationship = None

                # Find the part_of relationship on the current loaded ontology
                for rel in ontology.relationships():
                    if rel.id == &#34;part_of&#34;:
                        part_of_rel = rel
                        break

                # If a part_of relationship is found, compute the hierarchy of terms using it
                if part_of_rel is not None:
                    part_of_rel.transitive = False
                    print(&#34;Starting to compute super classes from part_of&#34;)
                    for term in ontology.terms():
                        for super_part_term in term.objects(part_of_rel):
                            if super_part_term.id in ontology.keys():
                                term.superclasses().add(super_part_term)
                    print(&#34;Finished to compute super classes from part_of&#34;)

                # Get the set of ancestors for the top level terms
                top_level_terms = [
                    ontology[term] for term in ontology_desc[&#34;top_level_terms&#34;]
                ]
                top_level_ancestors = []
                for top_level_term in top_level_terms:
                    top_level_ancestors.extend(
                        top_level_term.superclasses(with_self=False)
                    )
                top_level_ancestors = set(top_level_ancestors)

                # Iterate over the ontology terms and to get the hierarchy between them and the top level terms
                ontology_terms += [
                    self._parse_ontology_term(
                        term, top_level_terms, top_level_ancestors, part_of_rel
                    )
                    for term in ontology.terms()
                    if term.name is not None
                ]
                print(
                    f&#34;Finished processing {ontology_desc[&#39;id&#39;]}.{ontology_desc[&#39;format&#39;]}&#34;
                )

        # Transform the list of dictionaries representing terms to JSON
        ontology_terms_json = spark_session.sparkContext.parallelize(ontology_terms)

        # Read the JSON RDD to a Spark DataFrame so it can be written to disk as Parquet
        ontology_terms_df = spark_session.read.json(
            ontology_terms_json, schema=self.ONTOLOGY_SCHEMA, mode=&#34;FAILFAST&#34;
        )
        return ontology_terms_df

    def _parse_ontology_term(
        self,
        ontology_term: Term,
        top_level_terms,
        top_level_ancestors,
        part_of_rel: Relationship,
    ) -&gt; Dict:
        &#34;&#34;&#34;
        Takes in an ontology term, a list of top level terms, a list of top level ancestors
        (i.e. the ancestors of the top level terms),
        the relationship used to convey hierarchy and returns a list of dictionaries with all the hierarchical
        relationships between the terms and the top level terms.
        &#34;&#34;&#34;

        # Gather the direct children of the term
        children = [
            child_term for child_term in ontology_term.subclasses(1, with_self=False)
        ]

        # Get the direct parents of the term
        parents = [
            parent_term
            for parent_term in ontology_term.superclasses(1, with_self=False)
        ]

        # Get all the ancestors of the term
        ancestors = [
            ancestor_term
            for ancestor_term in ontology_term.superclasses(with_self=False)
        ]

        # Get all the ancestors based on the part_of relationship instead of relying on the is_a relationship
        if part_of_rel is not None:
            ancestors.extend(
                [ancestor_term for ancestor_term in ontology_term.objects(part_of_rel)]
            )

        # Get the term top level terms by intersecting its ancestors with the ontology top level terms
        term_top_level_terms = set(top_level_terms).intersection(set(ancestors))

        # Determine the intermediate terms
        intermediate_terms = (
            set(ancestors)
            .difference(set(top_level_terms))
            .difference(top_level_ancestors)
        )
        # Builds and returns the term dictionary containing all the related terms information
        return {
            &#34;id&#34;: ontology_term.id,
            &#34;term&#34;: self._parse_text(ontology_term.name),
            &#34;definition&#34;: self._parse_text(ontology_term.definition)
            if ontology_term.definition is not None
            else &#34;null&#34;,
            &#34;synonyms&#34;: [
                self._parse_text(synonym.description)
                for synonym in ontology_term.synonyms
                if synonym.type is &#34;EXACT&#34;
            ],
            &#34;alt_ids&#34;: list(ontology_term.alternate_ids),
            &#34;child_ids&#34;: [child_term.id for child_term in children],
            &#34;child_terms&#34;: [
                self._parse_text(child_term.name) for child_term in children
            ],
            &#34;child_definitions&#34;: [
                self._parse_text(child_term.definition)
                for child_term in children
                if child_term.definition is not None
            ],
            &#34;child_term_synonyms&#34;: self._get_synonym_list(children),
            &#34;parent_ids&#34;: [parent_term.id for parent_term in parents],
            &#34;parent_terms&#34;: [
                self._parse_text(parent_term.name) for parent_term in parents
            ],
            &#34;parent_definitions&#34;: [
                self._parse_text(parent_term.definition)
                for parent_term in parents
                if parent_term.definition is not None
            ],
            &#34;parent_term_synonyms&#34;: self._get_synonym_list(parents),
            &#34;intermediate_ids&#34;: [
                intermediate_term.id for intermediate_term in intermediate_terms
            ],
            &#34;intermediate_terms&#34;: [
                self._parse_text(intermediate_term.name)
                for intermediate_term in intermediate_terms
            ],
            &#34;intermediate_definitions&#34;: [
                self._parse_text(intermediate_term.definition)
                for intermediate_term in intermediate_terms
                if intermediate_term.definition is not None
            ],
            &#34;intermediate_term_synonyms&#34;: self._get_synonym_list(intermediate_terms),
            &#34;top_level_ids&#34;: [
                term_top_level_term.id for term_top_level_term in term_top_level_terms
            ],
            &#34;top_level_terms&#34;: [
                self._parse_text(term_top_level_term.name)
                for term_top_level_term in term_top_level_terms
            ],
            &#34;top_level_definitions&#34;: [
                self._parse_text(term_top_level_term.definition)
                for term_top_level_term in term_top_level_terms
                if term_top_level_term.definition is not None
            ],
            &#34;top_level_synonyms&#34;: self._get_synonym_list(term_top_level_terms),
            &#34;top_level_term_id&#34;: [
                f&#34;{term_top_level_term.id}___{self._parse_text(term_top_level_term.name)}&#34;
                for term_top_level_term in term_top_level_terms
            ],
        }

    def _get_synonym_list(self, terms: Iterable[Term]):
        &#34;&#34;&#34;
        Takes in a list of Terms and returns the list of synonyms for the given terms.
        &#34;&#34;&#34;
        flat_list = []
        for term in terms:
            for synonym in term.synonyms:
                flat_list.append(self._parse_text(synonym.description))
        return flat_list

    def _parse_text(self, definition: bytes):
        &#34;&#34;&#34;
        Parse an OBO definition text an return a valid Python str.
        &#34;&#34;&#34;
        if definition is None:
            return None
        return unicodedata.normalize(
            &#34;NFKD&#34;, definition.encode(&#34;iso-8859-1&#34;).decode(&#34;utf-8&#34;)
        )</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>luigi.contrib.spark.PySparkTask</li>
<li>luigi.contrib.spark.SparkSubmitTask</li>
<li>luigi.contrib.external_program.ExternalProgramTask</li>
<li>luigi.task.Task</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.ONTOLOGIES"><code class="name">var <span class="ident">ONTOLOGIES</span> : List[Dict[~KT, ~VT]]</code></dt>
<dd>
<div class="desc"><p>List on ontologies to process with their corresponding top level terms</p></div>
</dd>
<dt id="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.ONTOLOGY_SCHEMA"><code class="name">var <span class="ident">ONTOLOGY_SCHEMA</span> : pyspark.sql.types.StructType</code></dt>
<dd>
<div class="desc"><p>Schema of the resulting parquet file</p></div>
</dd>
<dt id="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.name"><code class="name">var <span class="ident">name</span></code></dt>
<dd>
<div class="desc"><p>Name of the Spark task</p></div>
</dd>
<dt id="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.obo_ontology_input_path"><code class="name">var <span class="ident">obo_ontology_input_path</span> : luigi.parameter.Parameter</code></dt>
<dd>
<div class="desc"><p>Path to the directory containing OBO files for MA, MPATH, EMAPA and MP.</p></div>
</dd>
<dt id="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.output_path"><code class="name">var <span class="ident">output_path</span> : luigi.parameter.Parameter</code></dt>
<dd>
<div class="desc"><p>Path of the output directory where ethe new parquet file will be generated.</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.app_options"><code class="name flex">
<span>def <span class="ident">app_options</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates the options pass to the PySpark job</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def app_options(self):
    &#34;&#34;&#34;
    Generates the options pass to the PySpark job
    &#34;&#34;&#34;
    return [
        self.obo_ontology_input_path,
        self.output().path,
    ]</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.extract_ontology_terms"><code class="name flex">
<span>def <span class="ident">extract_ontology_terms</span></span>(<span>self, spark_session: pyspark.sql.session.SparkSession, ontologies_path: str) ‑> pyspark.sql.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Takes in a spark session and the path containing cached OBO files and returns
a DataFrame that represents Ontology terms hierarchical relationships.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_ontology_terms(
    self, spark_session: SparkSession, ontologies_path: str
) -&gt; DataFrame:
    &#34;&#34;&#34;
    Takes in a spark session and the path containing cached OBO files and returns
    a DataFrame that represents Ontology terms hierarchical relationships.
    &#34;&#34;&#34;

    # List of ontology terms
    ontology_terms = []

    # This process can only be performed on local or client mode
    if ImpcConfig().deploy_mode in [&#34;local&#34;, &#34;client&#34;]:
        for ontology_desc in self.ONTOLOGIES:
            print(f&#34;Processing {ontology_desc[&#39;id&#39;]}.{ontology_desc[&#39;format&#39;]}&#34;)

            # Get the OBO file from the directory if MPATH otherwise get it from OBO foundry
            if ontology_desc[&#34;id&#34;] == &#34;mpath&#34;:
                ontology: Ontology = Ontology(ontologies_path + &#34;mpath.obo&#34;)
            else:
                ontology: Ontology = pronto.Ontology.from_obo_library(
                    f&#34;{ontology_desc[&#39;id&#39;]}.{ontology_desc[&#39;format&#39;]}&#34;
                )

            part_of_rel: Relationship = None

            # Find the part_of relationship on the current loaded ontology
            for rel in ontology.relationships():
                if rel.id == &#34;part_of&#34;:
                    part_of_rel = rel
                    break

            # If a part_of relationship is found, compute the hierarchy of terms using it
            if part_of_rel is not None:
                part_of_rel.transitive = False
                print(&#34;Starting to compute super classes from part_of&#34;)
                for term in ontology.terms():
                    for super_part_term in term.objects(part_of_rel):
                        if super_part_term.id in ontology.keys():
                            term.superclasses().add(super_part_term)
                print(&#34;Finished to compute super classes from part_of&#34;)

            # Get the set of ancestors for the top level terms
            top_level_terms = [
                ontology[term] for term in ontology_desc[&#34;top_level_terms&#34;]
            ]
            top_level_ancestors = []
            for top_level_term in top_level_terms:
                top_level_ancestors.extend(
                    top_level_term.superclasses(with_self=False)
                )
            top_level_ancestors = set(top_level_ancestors)

            # Iterate over the ontology terms and to get the hierarchy between them and the top level terms
            ontology_terms += [
                self._parse_ontology_term(
                    term, top_level_terms, top_level_ancestors, part_of_rel
                )
                for term in ontology.terms()
                if term.name is not None
            ]
            print(
                f&#34;Finished processing {ontology_desc[&#39;id&#39;]}.{ontology_desc[&#39;format&#39;]}&#34;
            )

    # Transform the list of dictionaries representing terms to JSON
    ontology_terms_json = spark_session.sparkContext.parallelize(ontology_terms)

    # Read the JSON RDD to a Spark DataFrame so it can be written to disk as Parquet
    ontology_terms_df = spark_session.read.json(
        ontology_terms_json, schema=self.ONTOLOGY_SCHEMA, mode=&#34;FAILFAST&#34;
    )
    return ontology_terms_df</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>self, sc: pyspark.context.SparkContext, *args: Any)</span>
</code></dt>
<dd>
<div class="desc"><p>DCC Extractor job runner</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main(self, sc: SparkContext, *args: Any):
    &#34;&#34;&#34;
    DCC Extractor job runner
    &#34;&#34;&#34;
    input_path = args[0]
    output_path = args[1]

    spark = SparkSession(sc)
    ontology_df = self.extract_ontology_terms(spark, input_path)
    ontology_df.write.mode(&#34;overwrite&#34;).parquet(output_path)</code></pre>
</details>
</dd>
<dt id="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.output"><code class="name flex">
<span>def <span class="ident">output</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the full parquet path as an output for the Luigi Task
(e.g. impc/dr15.2/parquet/impc_ontology_term_hierarchy_parquet)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def output(self):
    &#34;&#34;&#34;
    Returns the full parquet path as an output for the Luigi Task
    (e.g. impc/dr15.2/parquet/impc_ontology_term_hierarchy_parquet)
    &#34;&#34;&#34;
    return ImpcConfig().get_target(
        f&#34;{self.output_path}impc_ontology_term_hierarchy_parquet&#34;
    )</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<div style="max-width: 300px; text-align: center">
<img src="https://www.mousephenotype.org/wp-content/themes/impc/images/IMPC_10_YEAR_Logo.svg" alt="IMPC Logo">
</div>
<h1 style="text-align: center; max-width: 300px;">IMPC ETL</h1>
<h2 style="text-align: center; max-width: 300px;">Reference Documentation</h2>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="impc_etl.jobs.extract" href="index.html">impc_etl.jobs.extract</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor" href="#impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor">OntologyTermHierarchyExtractor</a></code></h4>
<ul class="">
<li><code><a title="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.ONTOLOGIES" href="#impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.ONTOLOGIES">ONTOLOGIES</a></code></li>
<li><code><a title="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.ONTOLOGY_SCHEMA" href="#impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.ONTOLOGY_SCHEMA">ONTOLOGY_SCHEMA</a></code></li>
<li><code><a title="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.app_options" href="#impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.app_options">app_options</a></code></li>
<li><code><a title="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.extract_ontology_terms" href="#impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.extract_ontology_terms">extract_ontology_terms</a></code></li>
<li><code><a title="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.main" href="#impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.main">main</a></code></li>
<li><code><a title="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.name" href="#impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.name">name</a></code></li>
<li><code><a title="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.obo_ontology_input_path" href="#impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.obo_ontology_input_path">obo_ontology_input_path</a></code></li>
<li><code><a title="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.output" href="#impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.output">output</a></code></li>
<li><code><a title="impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.output_path" href="#impc_etl.jobs.extract.ontology_hierarchy_extractor.OntologyTermHierarchyExtractor.output_path">output_path</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p><span></span></p>
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>